[
  {
    "objectID": "Mouse/1_DataProcessing.html",
    "href": "Mouse/1_DataProcessing.html",
    "title": "1. Data Pre-processing",
    "section": "",
    "text": "1.1. Download fastQ files from ENA\nAfter the download of fastQ files, they were concatenated in order to obtain",
    "crumbs": [
      "Mouse analysis",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>1. Data Pre-processing</span>"
    ]
  },
  {
    "objectID": "Mouse/1_DataProcessing.html#download-fastq-files-from-ena",
    "href": "Mouse/1_DataProcessing.html#download-fastq-files-from-ena",
    "title": "1. Data Pre-processing",
    "section": "",
    "text": "#!/bin/bash\n# [matterhorn]\n# AUTHOR: Alba Mendez Alejandre\n# DESCRIPTION: Download the raw fastQ via ftp from ENA. The metadata is stored in the downloaded csv. \n# DATE: 10/06/2024\n\nseq_ids=(\"run1\" \"run2\")\n\nfor seq_number in \"${seq_ids[@]}\"; do\n\n    # Path to our CSV file\n    CSV_FILE=\"/mnt/D/mcGinn_2021/data_info/${seq_number}_download.csv\"\n\n    # Directory where we are going to download the data (bam and fastq)\n    DOWNLOAD_DIR=\"./${seq_number}_run1/${seq_number}_adult_P70\"\n\n    # Create the directory if it doesn't exist\n    mkdir -p \"$DOWNLOAD_DIR\"\n\n    # Iterate through each line in the CSV file\n    { \n        read # skip header\n        while IFS=, read -r name source_name bam_uri R1_fastq_uri R2_fastq_uri I1_fastq_uri # these are the columns of the file\n        do\n            # Skip header\n            if [[ $name == \"name\" ]]; then\n            continue\n            fi\n\n            # Ensure the URI is not empty\n            if [[ -z $R1_fastq_uri ]]; then\n            echo \"Empty URI for name: $name\"\n            continue\n            fi\n\n            # Download R1_fastq_uri\n            curl -L -o \"${DOWNLOAD_DIR}/${name}_$(basename \"$R1_fastq_uri\")\" \"$R1_fastq_uri\"\n            \n            if [[ -z $R2_fastq_uri ]]; then\n            echo \"Empty URI for name: $name\"\n            continue\n            fi\n\n            # Download R2_fastq_uri\n            curl -L -o \"${DOWNLOAD_DIR}/${name}_$(basename \"$R2_fastq_uri\")\" \"$R2_fastq_uri\"\n            \n            if [[ -z $I1_fastq_uri ]]; then\n            echo \"Empty URI for name: $name\"\n            continue\n            fi\n\n            # Download I1_fastq_uri\n            curl -L -o \"${DOWNLOAD_DIR}/${name}_$(basename \"$I1_fastq_uri\")\" \"$I1_fastq_uri\"\n        \n            if [[ -z $bam_uri ]]; then\n            echo \"Empty URI for name: $name\"\n            continue\n            fi\n\n        done &lt; \"$CSV_FILE\"\n    }\ndone\n./download_fastq.sh",
    "crumbs": [
      "Mouse analysis",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>1. Data Pre-processing</span>"
    ]
  },
  {
    "objectID": "Mouse/1_DataProcessing.html#quality-control-with-multiqc",
    "href": "Mouse/1_DataProcessing.html#quality-control-with-multiqc",
    "title": "1. Data Pre-processing",
    "section": "1.2 Quality control with MultiQC",
    "text": "1.2 Quality control with MultiQC\nView MultiQC report for sequencing run 2\nView MultiQC report for sequencing run 1",
    "crumbs": [
      "Mouse analysis",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>1. Data Pre-processing</span>"
    ]
  },
  {
    "objectID": "Mouse/1_DataProcessing.html#star-aligment",
    "href": "Mouse/1_DataProcessing.html#star-aligment",
    "title": "1. Data Pre-processing",
    "section": "1.3. STAR aligment",
    "text": "1.3. STAR aligment\nSeparate scripts were used for each sequencing session (names as run1 and run2 for simplification).\n#!/bin/bash\n# [folia]\n# This script must be executed in the server where we want to run STAR\n\n# activate env where we have installed STAR\nsource /home/albax/miniforge3/bin/activate STAR\n\nFOLIA_BASE=\"/home/albax/mcGinn_2021\"\nMATTERHORN_BASE=\"/media/storage/mcGinn_2021\"\nCONCATENATED_RUNS_DIR=\"${MATTERHORN_BASE}/concatenated_runs/sample_concatenated\"\n\n\nSAMPLE_NAMES=(\"lib1\" \"lib2\" \"lib3\" \"lib4\" \"lib5\" \"lib6\" \"lib7\" \"lib8\") # list of samples to proccess\n\ni=0\nfor SAMPLE in \"${SAMPLE_NAMES[@]}\"; \ndo\n    i=$((i + 1))\n\n    SAMPLE_DIR=\"${CONCATENATED_RUNS_DIR}/${SAMPLE}\"\n    LOCAL_SAMPLE_DIR=\"${FOLIA_BASE}${SAMPLE_DIR}\"\n    echo \"Processing sample: ${SAMPLE}\"\n\n    R2_FILE=\"${SAMPLE_DIR}/${SAMPLE}*R2*run1.fastq.gz\"\n    R1_FILE=\"${SAMPLE_DIR}/${SAMPLE}*R1*run1.fastq.gz\"\n\n    # Files' pull from matterhorn to folia\n    rsync -avR --progress -hh \"alba@matterhorn:${R2_FILE}\" \"${FOLIA_BASE}\"\n    rsync -avR --progress -hh \"alba@matterhorn:${R1_FILE}\" \"${FOLIA_BASE}\"\n\n    LOCAL_R2_FILE=\"${FOLIA_BASE}${R2_FILE}\"\n    LOCAL_R1_FILE=\"${FOLIA_BASE}${R1_FILE}\"\n\n    echo \"R2 file (folia): ${LOCAL_R2_FILE}\"\n    echo \"R1 file (folia): ${LOCAL_R1_FILE}\"\n    \n    cd ${FOLIA_BASE}\n    mkdir -p \"${FOLIA_BASE}/STAR_out/${SAMPLE}\"\n\n  # Process files\n#   ~/miniforge3/envs/STAR/bin/STAR \\\n    STAR --runMode alignReads --genomeDir /home/albax/reference_genomes/STAR_indexes/Mus_musculus/mm10 --outFileNamePrefix STAR_out/SLX-17937_${SAMPLE} --readFilesCommand zcat --readFilesIn ${LOCAL_R2_FILE} ${LOCAL_R1_FILE} --soloType CB_UMI_Simple --soloCBwhitelist /home/albax/mcGinn_2021/STAR_whitelist/3M-february-2018.txt --soloCBstart 1 --soloCBlen 16 --soloUMIstart 17 --soloUMIlen 12 --soloStrand Forward --soloFeatures Gene GeneFull Velocyto --outSAMattributes NH HI AS nM CR UR CB UB GX GN sM sS sQ --outSAMtype BAM SortedByCoordinate --runThreadN 4\n\n    if [[ $? -ne 0 ]]; then\n        echo \"STAR alignment failed for sample ${SAMPLE}.\"\n        continue\n    fi\n\n        # Transfer back to matterhorn\n    ssh alba@matterhorn \"mkdir -p /media/storage/mcGinn_2021/STARalignment/${SAMPLE}/\"\n\n    rsync -av --progress -hh ${FOLIA_BASE}/STAR_out/*${SAMPLE}* alba@matterhorn:${MATTERHORN_BASE}/STARalignment/${SAMPLE}/\n\n    # Remove to save space\n    echo -e \"\\n[ $(date +'%Y/%m/%d %T.%3N') ] Finished processing ${SAMPLE}\"\n    rm ${LOCAL_R1_FILE} ${LOCAL_R2_FILE}\n    rm -r ${FOLIA_BASE}/STAR_out/*${SAMPLE}*/\n\ndone\n\n# clean up base directory\nrm -r ${FOLIA_BASE}/STAR_out\n\nconda deactivate\n./STAR_alignment.sh\nGenerate the reference genome indexed file\n#!/bin/bash\n\ncd ~/reference_genomes/\nmkdir STAR_indexes\nmkdir logs\n\n# path to star\n~/miniforge3/envs/STAR/bin/STAR \\\n            --runThreadN 4 \\\n        --runMode genomeGenerate \\\n        --genomeDir ./STAR_indexes/Mus_musculus/mm10 \\\n        --genomeFastaFiles ./Mus_musculus_C57BL-6J/Mus_musculus.GRCm38.dna.primary_assembly.fa \\\n        --sjdbGTFfile ./Mus_musculus_C57BL-6J/Mus_musculus.GRCm38.97.gtf \\\n                                |& tee logs/star_index.log",
    "crumbs": [
      "Mouse analysis",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>1. Data Pre-processing</span>"
    ]
  },
  {
    "objectID": "Mouse/1_DataProcessing.html#create-seurat-object",
    "href": "Mouse/1_DataProcessing.html#create-seurat-object",
    "title": "1. Data Pre-processing",
    "section": "1.4. Create Seurat object",
    "text": "1.4. Create Seurat object\nThe next step is to create the seurat object with the count matrices obtained from STARsolo, with spliced, unspliced and gene matrices.\n\n\n\n\n\n\n[The file is named “1-4_merge_seurat_fixedrank.R”]",
    "crumbs": [
      "Mouse analysis",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>1. Data Pre-processing</span>"
    ]
  },
  {
    "objectID": "Mouse/2_ClusteringCellAnnotation.html",
    "href": "Mouse/2_ClusteringCellAnnotation.html",
    "title": "2. Clustering and Cell annotation",
    "section": "",
    "text": "Import libraries\n.libPaths(\"/home/albax/miniforge3/envs/seurat_v4/lib/R/library\")\n\nif(.Platform$OS.type == \"linux\") Sys.setenv(PATH= paste(\"/home/albax/miniforge3/envs/seurat_v4/lib\",Sys.getenv()[\"PATH\"],sep=\";\"))\n\nlibrary(reticulate)\n\nuse_condaenv(\"/home/albax/miniforge3/envs/seurat_v4\", required = TRUE)\npy_config()\n\nimport(\"numpy\")\nimport(\"leidenalg\")\nimport(\"pandas\")\n\nsuppressMessages(library(Seurat))\nsuppressMessages(library(dplyr))\nsuppressMessages(library(DropletUtils)) #QC filtering\nsuppressMessages(library(ggplot2))\nsuppressMessages(library(plotly))\nsuppressMessages(library(SingleCellExperiment))\nsuppressMessages(library(clustree))\nsuppressMessages(library(httpgd))\nsuppressMessages(library(patchwork))\n# suppressMessages(library(BPCells)) # for on-disk memory\n\n\nsuppressMessages(library(future))\nsuppressMessages(library(future.apply))\nsuppressMessages(library(BiocParallel))\n\n\n# For data management\nsuppressMessages(library(tidyverse))\nsuppressMessages(library(Matrix))\nsuppressMessages(library(gtools))\nsuppressMessages(library(R.utils))\n\n# For plotting\nsuppressMessages(library(RColorBrewer))\nsuppressMessages(library(viridis))\nsuppressMessages(library(gplots))\nsuppressMessages(library(gridExtra))\nsuppressMessages(library(ggrepel))\nsuppressMessages(library(ggridges))\n\n# for matrix \nlibrary(Matrix)\nlibrary(Matrix.utils)\n\ncolor.list &lt;- RColorBrewer::brewer.pal(12,\"Paired\")\ncolor.list &lt;- c(color.list,RColorBrewer::brewer.pal(12,\"Set3\"))\n\n# Palette from orange to violet\npalette &lt;- scale_color_viridis_c(option = \"plasma\", direction = -1) # continue colors palette\npalette_d &lt;- scale_color_viridis_d(option = \"turbo\", direction = 1) # discrete colors palette\n\nname_order &lt;- c(\"lib1\", \"lib2\", \"lib3\", \"lib4\", \"lib5\", \"lib6\", \"lib6\", \"lib7\") # fixed library order to plot the results\n\nsetwd(\"/home/albax/mcGinn_2021\")",
    "crumbs": [
      "Mouse analysis",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>2. Clustering and Cell annotation</span>"
    ]
  },
  {
    "objectID": "Mouse/2_ClusteringCellAnnotation.html#load-data",
    "href": "Mouse/2_ClusteringCellAnnotation.html#load-data",
    "title": "2. Clustering and Cell annotation",
    "section": "Load data",
    "text": "Load data\nFirst, we load our rds object, and we get only the data from the assay “gene”. Note that we have different rds objects, each of them contains different step versions (non-filtered, filtered, annotated), in order to maintain consistency and avoid errors and accidental deletes.\n\n# Esoph &lt;- readRDS(file = \"./results/esoph_star_filtfixed_mm10.rds\") # this is with mm10 alignment\nEsoph # 57186 genes genes accross 46321 cells\n# An object of class Seurat \n# 171558 features across 46321 samples within 3 assays \n# Active assay: gene (57186 features, 0 variable features)\n#  2 layers present: counts, data\n#  2 other assays present: spliced, unspliced\n\n# Esoph_clusts &lt;- readRDS(file = \"./output/esoph_star_clusts_mm10.rds\") # after clustering, with PCA, tSNE, UMAP, etc. Without filtering. \n\n# Esoph_filt &lt;- readRDS(file = \"./output/esoph_star_filtered_mm10_vep_annot.rds\") # also load the already filtered seurat object (which doesnt contain clusters 4 and 7)\nEsoph_filt # 57186 genes genes accross 39763 cells\n# An object of class Seurat \n# 250024 features across 39763 samples within 5 assays \n# Active assay: RNA (57186 features, 0 variable features)\n#  2 layers present: counts, data\n#  4 other assays present: gene, spliced, unspliced, SCT\n#  3 dimensional reductions calculated: pca, tsne, umap\n\nEsoph_filt &lt;- readRDS(file = \"./output/esoph_star_filtered_mm10_vep_annot_rep.rds\") # seurat object with annotated clones and additional info\nEsoph_filt\n# An object of class Seurat \n# 250024 features across 39763 samples within 5 assays \n# Active assay: RNA (57186 features, 0 variable features)\n#  2 layers present: counts, data\n#  4 other assays present: gene, spliced, unspliced, SCT\n#  3 dimensional reductions calculated: pca, tsne, umap\n\nThe features(genes) are automatically collapsed -&gt; there are no duplicated rows in any of the assays.\nLook for duplicated genes:\n\ngene_features &lt;- rownames(Esoph[[\"unspliced\"]])\nduplicated_genes &lt;- gene_features[duplicated(gene_features)]\nprint(\"Duplicated genes in the 'gene' assay:\")\nprint(duplicated_genes)",
    "crumbs": [
      "Mouse analysis",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>2. Clustering and Cell annotation</span>"
    ]
  },
  {
    "objectID": "Mouse/2_ClusteringCellAnnotation.html#qc-stats",
    "href": "Mouse/2_ClusteringCellAnnotation.html#qc-stats",
    "title": "2. Clustering and Cell annotation",
    "section": "2.1. QC stats",
    "text": "2.1. QC stats\nWe are going to perform everything only in the “spliced” assay.\n\nDefaultAssay(Esoph) &lt;- \"spliced\" # change active assay to spliced\nhead(Esoph@meta.data, 5) #it contains nCount and nFeature for each assay\n\nTypically, we want to filter: - Blood cells (erythrocites) - The percentage of reads that map to the mitochondrial genome - Low-quality / dying cells often exhibit extensive mitochondrial contamination - We calculate mitochondrial QC metrics with the PercentageFeatureSet() function which calculates the percentage of counts originating from a set of features - We use the set of all genes starting with MT-(^MT) as a set of mitochondrial genes low quality barcodes (a treshold)\n\nEmpty barcodes (using a treshold)\nThe number of unique genes detected in each cell.\n\nLow-quality cells or empty droplets will often have very few genes\nCell doublets or multiplets may exhibit an aberrantly high gene count\n\nSimilarly, the total number of molecules detected within a cell (correlates strongly with unique genes)\n\nWe have already filtered our data with barcodes ranks, and now we are going to inspect the seurat object in order to decide how we filter it spoiler: we end up filtering using the clusterization (7 clusters) shown in umap with resolution 0.3 (which we decide viewing clustree), where we are going to delete clusters 4 and 7, as they belong to fibroblasts (Vim marker) or have really high mt percent.\n\nDetect MT genes\n\nhead(row.names(Esoph)) # first genes\nEsoph[[\"percent.mt\"]] &lt;- PercentageFeatureSet(Esoph, assay = \"spliced\", pattern = \"^mt-\") # calculate mitochondrial percent\nhead(Esoph@meta.data, 5)\n\n# we have NaN values in percent.mt because percentage is calculated by percentage is (x$nCount_RNA/x$percent.mt)*100  , and therefore there are 0 values for the nCount slot and 0 mitochondrial gene counts for the barcode. \n\n# Delete barcodes\n# Esoph &lt;- subset(Esoph, subset = !is.na(\"percent.mt\")) # exclude NaN values\n\nVisualize QC metrics\n\nVlnPlot(Esoph, features = c(\"nFeature_spliced\", \"nCount_spliced\", \"nFeature_unspliced\", \"nCount_unspliced\", \"percent.mt\"), ncol = 5)  \n# VlnPlot(Esoph, features =  \"percent.mt\", ncol = 1) +\n       scale_y_continuous(breaks = seq(0, 100, by = 5)) \n# VlnPlot(Esoph, features =  \"nFeature_spliced\", ncol = 1) +\n       scale_y_continuous(breaks = seq(0, 10000, by = 500)) \n# VlnPlot(Esoph, features =  \"nCount_spliced\", ncol = 1) +\n       scale_y_continuous(breaks = seq(0, 1000000, by = 10000))\nVlnPlot(Esoph, features =  \"nFeature_spliced\", split.by = \"Sequencing_ID\", ncol = 1) +\n       scale_y_continuous(breaks = seq(0, 10000, by = 500)) # frecuencia genes en cada sequencing\n\n# plot(density(Esoph$nFeature_spliced)) # kernel density plot (alternative to hist())\n# plot(density(Esoph$percent.mt)) # kernel density plot (alternative to hist())\n\nVlnPlot(Esoph_filt, features=\"nFeature_spliced\", split.by=\"Sequencing_ID\")\n\n\nplot1 &lt;- FeatureScatter(Esoph, feature1 = \"nCount_spliced\", feature2 = \"percent.mt\")\nplot2 &lt;- FeatureScatter(Esoph, feature1 = \"nCount_spliced\", feature2 = \"nFeature_spliced\")\nplot3 &lt;- FeatureScatter(Esoph, feature1 = \"nCount_spliced\", feature2 = \"nCount_unspliced\")\nplot1 + plot2 + plot3\n\nAccording to the plots we have seen, we are going to filter the Esoph object (by eye).\nThe original paper filtered the cells according to: - Cells that have &gt;15% mitochondrial counts - Cells that have unique feature counts less than 1200 - Genes expressed in fewer than 3 cells But we are not going to do this.\n\n## General statistics post-second filtering:\n# Proportion of UMIs that are from unspliced transcripts:\n# (kallisto | bus counts reads that are partially intronic and partially exonic as unspliced while velocyto throws away many reads, reason why it ends with smaller proportion - see https://github.com/velocyto-team/velocyto.py/issues/148)\nsum(Esoph$nCount_unspliced) / (sum(Esoph$nCount_spliced) + sum(Esoph$nCount_unspliced)) # 0.1198788 mm39\n# [1] 0.1281474 mm10\n\n# Most barcodes now have &gt;&gt; 0 or 1 UMIs detected:\nfilt2_count &lt;- Matrix::colSums(Esoph)\nsummary(filt2_count) # median genes = 13632 mm39\n# median genes = 11900 mm10\n\n# Make a copy of spliced assay (for purpose of unambiguous exportation and interpretation in scvelo)\nEsoph[[\"RNA\"]] &lt;- Esoph[[\"spliced\"]]\nEsoph # spliced assay keeps as default assay used as input for downstream normalization etc. (but not modified)",
    "crumbs": [
      "Mouse analysis",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>2. Clustering and Cell annotation</span>"
    ]
  },
  {
    "objectID": "Mouse/2_ClusteringCellAnnotation.html#normalization-feature-selection-scaling",
    "href": "Mouse/2_ClusteringCellAnnotation.html#normalization-feature-selection-scaling",
    "title": "2. Clustering and Cell annotation",
    "section": "2.2. Normalization, feature selection, scaling",
    "text": "2.2. Normalization, feature selection, scaling\n\nEsoph &lt;- SCTransform(Esoph, assay = \"spliced\", new.assay.name = \"SCT\")\n# creates SCT assay (that becomes default)\n\n# Highly-variable features (between cells):  # 3000 by default\n# Identify the 10 most highly variable genes\ntop10 &lt;- head(VariableFeatures(Esoph), 10)\n# Linear scaling is restricted to highly-variable features by default: Esoph[[\"SCT\"]]@scale.data\n\n\n# plot variable features with labels\nLabelPoints(plot = VariableFeaturePlot(object = Esoph[[\"SCT\"]], selection.method = \"sct\"), points = top10, repel = TRUE, xnudge = 0, ynudge = 0)\n\n\ni. Dimensional reduction (PCA)\nObservation: Makes most sense to plot RNA velocity over cell embeddings from the SCT matrix (built from spliced, not unspliced counts; i.e. we seek arrows as predictions from CURRENT state)\n\nDefaultAssay(Esoph) &lt;- \"SCT\" # already default, but just in case\nEsoph &lt;- RunPCA(Esoph, verbose = FALSE) # by default, based on variable features\n\n\n# Summary of genes defining most variability: (higher PCA score)\nprint(Esoph[[\"pca\"]], dims = 1:5, nfeatures = 5)\nVizDimLoadings(Esoph, dims = 1:2, reduction = \"pca\")\n\n# PCA plot:\nDimPlot(Esoph, dims = c(1,2), reduction = \"pca\", pt.size = 0.5) # change the dimensions as you want\n\nHeatmap of genes and cells with highest PCA score (a quick supervised analysis of sources of variation)\n\nDimHeatmap(Esoph, dims = 1, cells = 500, balanced = TRUE) # picks 500 most extreme cells on each end of PCA1 spectrum for 15 top differentiating genes\nDimHeatmap(Esoph, dims = 1:15, cells = 500, balanced = TRUE)\n\n\n# Set the threshold of significant dimensions based on conjunction of JackStraw, ElbowPlot and Supervised Heatmaps outcome before\n\n## Significant dimensions: determine most relevant sources of variability\n# Extensive technical noise is reduced when eliminating minor components, so top principal components represent a robust compression of the dataset.\n# ElbowPlot (heuristic; based on % variance explained by each PC component)\nElbowPlot(Esoph) # use 17\n\n\n\nii. Non-linear dimensional representation\nSimplifies the complex manifold of the data in a super-reduced dimensional space for visualization. We should run this after PCA, in order to further reduce the dimensionality or our dataset. Later, we can run FindClusters() with whatever dimension we prefer.\n\n## tSNE\nEsoph &lt;- RunTSNE(Esoph, dims = 1:17, verbose = FALSE)\n\n# saveRDS(Esoph, file = \"./output/esoph_star_tsne_mm10.rds\")\n\ntsne_plot_15 &lt;- DimPlot(Esoph, reduction = \"tsne\", pt.size = 0.5) # _ clusters\ntsne_plot_15\n\nBe careful when running this chunk, as umap can consume a lot of cpu:\n\n## UMAP\nEsoph &lt;- RunUMAP(Esoph, reduction = \"pca\", dims = 1:17)\n# saveRDS(Esoph, file = \"./output/esoph_star_clusts_mm10.rds\") # contains also FindNeighbours()\n\n\numap_plot_15 &lt;- DimPlot(Esoph, reduction = \"umap\", pt.size = 0.5, label=TRUE)\numap_plot_15\n\n\nunique_names &lt;- sapply(strsplit(colnames(Esoph), \"-\"), function(x) paste(x[2], x[3], sep = \"-\"))\n# Add this information as metadata\nEsoph$unique_name &lt;- unique_names\n\n# Create a DimPlot colored by the unique names\nDimPlot(Esoph, reduction = \"umap\", pt.size = 0.5, label=FALSE, group.by = 'unique_name') # group by a column from metadata\n\n\n\niii. Clustering (graph-based)\n\nCellular distance metric: euclidean distance (on PCAs)\nEmbedding cells in a graph structure - for example a K-nearest neighbor (KNN) graph, with edges drawn between cells with similar feature expression patterns\n\n\nFind Neighbours (KNN)\n\nEsoph &lt;- FindNeighbors(Esoph, reduction = \"pca\", dims = 1:17) # dims based on first N components (from pca reduction)",
    "crumbs": [
      "Mouse analysis",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>2. Clustering and Cell annotation</span>"
    ]
  },
  {
    "objectID": "Mouse/2_ClusteringCellAnnotation.html#find-clusters",
    "href": "Mouse/2_ClusteringCellAnnotation.html#find-clusters",
    "title": "2. Clustering and Cell annotation",
    "section": "2.3. Find Clusters",
    "text": "2.3. Find Clusters\nAlgorithm for modularity optimization (1 = original Louvain algorithm; 2 = Louvain algorithm with multilevel refinement; 3 = SLM algorithm; 4 = Leiden algorithm). Leiden requires the leidenalg python. - Louvain algorithm: Partitioning into highly interconnected ‘quasi-cliques’ or ‘communities’, optimizing a modularity target function. It may yield arbitrarily badly connected communities. In the worst case, communities may even be disconnected, especially when running the algorithm iteratively. - Leiden algorithm: when applied iteratively, it converges to a partition in which all subsets of all communities are locally optimally assigned. Furthermore, by relying on a fast local move approach, the Leiden algorithm runs faster than the Louvain algorithm.\nWe will use Leiden algorith (algorithm = 4, method = “igraph”) https://www.nature.com/articles/s41598-019-41695-z\n\n# Esoph &lt;- FindClusters(Esoph, resolution = seq(0.2, 1.2, by = 0.2), algorithm = 4) # this consumed too much memory...\n\nEsoph &lt;- FindClusters(Esoph, resolution = 0.1, algorithm = 4, method = \"igraph\") \nEsoph &lt;- FindClusters(Esoph, resolution = 0.2, algorithm = 4, method = \"igraph\") \nEsoph &lt;- FindClusters(Esoph, resolution = 0.3, algorithm = 4, method = \"igraph\") \nEsoph &lt;- FindClusters(Esoph, resolution = 0.4, algorithm = 4, method = \"igraph\") \nEsoph &lt;- FindClusters(Esoph, resolution = 0.6, algorithm = 4, method = \"igraph\") \nEsoph &lt;- FindClusters(Esoph, resolution = 0.8, algorithm = 4, method = \"igraph\") \nEsoph &lt;- FindClusters(Esoph, resolution = 1.0, algorithm = 4, method = \"igraph\") \nEsoph &lt;- FindClusters(Esoph, resolution = 1.2, algorithm = 4, method = \"igraph\") \n\n\n# To decide how many clusters we should annotate, with the signatures we decide\nclustree(Esoph, prefix = \"SCT_snn_res.\") # we are going to use resolution 0.2 for Esoph in mm10\n\n\n# Idents() contains cluster info\nhead(Idents(Esoph), 10) # looks at cluster IDs of the first 10 cells\n\n\nDimPlot(Esoph, group.by = \"SCT_snn_res.0.2\") & palette_d\nDimPlot(Esoph, group.by = \"SCT_snn_res.0.3\") & palette_d\nDimPlot(Esoph, group.by = \"SCT_snn_res.0.4\") & palette_d\n\nDimPlot(Esoph, group.by = \"SCT_snn_res.0.2\", split.by = \"condition\") & palette_d\n\nFinding different cell types that may not be epithelial, due to contamination, experiment design, whatever…\nCell markers (they may vary between mouse/human): - Hematopoetic cells -&gt; Cd34 - Fibroblasts -&gt; Vim\n\nFeaturePlot(Esoph, features = \"Cd34\") & palette # marker for hematopoietic stem cells (immune)\nFeaturePlot(Esoph, features = \"Vim\") & palette # marker for fibroblasts\n\nThanks to the plots above, we can clearly see that we have fibroblast cells that belong to cluster number 7 (when using resolution 0.2).\nQuality control plots with umap:\n\n# number of genes per cell\nFeaturePlot(Esoph, features = \"nFeature_spliced\") & palette # no huge heterogeneities\nFeaturePlot(Esoph, features = \"percent.mt\") & palette \n\nWe an see that the top “leaf” of our umap has low-quality cells, with few genes, and very high MT%. These cells belong to cluster 4 (when using resolution 0.2).\n\n# Select resolution for Seurat Clusters:\nIdents(Esoph) = Esoph$SCT_snn_res.0.2\nEsoph$seurat_clusters = Esoph$SCT_snn_res.0.2\n\n\n## Remaining annotation using top markers for every cluster compared to all remaining ones, reporting only the positive ones\n# Esoph.markers &lt;- FindAllMarkers(Esoph, only.pos = TRUE, min.pct = 0.25, logfc.threshold = 0.25) # restrict to features with a min of 0.25 logFC\n\n# write.table(Esoph.markers, file = './output/Esoph_markers.txt', col.names = TRUE, row.names = TRUE, sep = '\\t')\n\nRESULTS:\nWhen we plot the UMAP, we can see that there are: - Region with high MT proportion (belongs to cluster 4) - Two regions that seem to be different type of cells. - The region from the upper-left seems to be fibroblasts, bc if we run DimPlot(Esoph, features = features = c(“Vim”)), it colours. Vim(vimentin) is a typical fibroblast marker. - The other region must be further investigated to detect what is it. - Also, the cluster 4 looks like a “batch” that represents the whole data - Cluster 6 is specific of sample Old_DEN, which could be biological evidences!!\nAfter annotating and saving the preliminar results, we proceed by deleting the cluster number 4, as it is very heterogenous and somehow represents all the clusters in the data.\nWe also delete cluster number 7, as they are fibroblasts.\nDelete cluster 4 and 7:\n\nEsoph_filt &lt;- subset(x = Esoph, idents = c(\"4\", \"7\"), invert = TRUE)\n# mm10\n# An object of class Seurat \n# 250504 features across 39763 samples within 5 assays \n# Active assay: SCT (21760 features, 3000 variable features)\n#  3 layers present: counts, data, scale.data\n#  4 other assays present: gene, spliced, unspliced, RNA\n#  3 dimensional reductions calculated: pca, tsne, umap",
    "crumbs": [
      "Mouse analysis",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>2. Clustering and Cell annotation</span>"
    ]
  },
  {
    "objectID": "Mouse/2_ClusteringCellAnnotation.html#cell-annotation",
    "href": "Mouse/2_ClusteringCellAnnotation.html#cell-annotation",
    "title": "2. Clustering and Cell annotation",
    "section": "2.4. Cell annotation",
    "text": "2.4. Cell annotation\n\nEsoph.markers &lt;- FindAllMarkers(Esoph_filt, only.pos = TRUE, min.pct = 0.25, logfc.threshold = 0.25)\n\nwrite.table(Esoph.markers, file = './output/Esoph_markers_clusts.txt', col.names = TRUE, row.names = TRUE, sep = '\\t')\n\nTopMarkers &lt;- Esoph.markers %&gt;% \n  group_by(cluster) %&gt;% top_n(n = 5, wt = avg_log2FC) # show just top 5 per cluster\n\n\nTopMarkers %&gt;% write.csv(\"./output/Esoph_TopMarkers.csv\")\ncluster3_markers &lt;- TopMarkers[TopMarkers$cluster == 3, ]  # Suprabasal\ncluster4_markers &lt;- TopMarkers[TopMarkers$cluster == 4, ]  # Mito-rich\ncluster6_markers &lt;- TopMarkers[TopMarkers$cluster == 6, ]  # Epi_DEN\ncluster7_markers &lt;- TopMarkers[TopMarkers$cluster == 7, ]  # Fibroblasts",
    "crumbs": [
      "Mouse analysis",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>2. Clustering and Cell annotation</span>"
    ]
  },
  {
    "objectID": "Mouse/2_ClusteringCellAnnotation.html#re-normalization-and-clustering-of-filtered-object",
    "href": "Mouse/2_ClusteringCellAnnotation.html#re-normalization-and-clustering-of-filtered-object",
    "title": "2. Clustering and Cell annotation",
    "section": "2.5. Re-normalization and clustering of filtered object",
    "text": "2.5. Re-normalization and clustering of filtered object\nRepeat normalization, PCA, tSNE and umap:\n\nEsoph_filt &lt;- SCTransform(Esoph_filt, assay = \"spliced\", new.assay.name = \"SCT\")\nDefaultAssay(Esoph_filt) &lt;- \"SCT\" # already default, but just in case\n\nEsoph_filt &lt;- RunPCA(Esoph_filt, verbose = FALSE)\n\nElbowPlot(Esoph_filt) # 17 dimensions\n\nEsoph_filt &lt;- RunTSNE(Esoph_filt, dims = 1:17, verbose = FALSE, reduction = \"pca\", reduction.name = \"tsne\", reduction.key = \"tSNE\")\n\nEsoph_filt &lt;- RunUMAP(Esoph_filt, reduction = \"pca\", dims = 1:17, reduction.name = \"umap\")\n\n\nEsoph_filt &lt;- FindNeighbors(Esoph_filt, reduction = \"pca\", dims = 1:17)\n\nEsoph_filt &lt;- FindClusters(Esoph_filt, resolution = 0.1, algorithm = 4, method = \"igraph\") \nEsoph_filt &lt;- FindClusters(Esoph_filt, resolution = 0.2, algorithm = 4, method = \"igraph\") \nEsoph_filt &lt;- FindClusters(Esoph_filt, resolution = 0.3, algorithm = 4, method = \"igraph\") \nEsoph_filt &lt;- FindClusters(Esoph_filt, resolution = 0.4, algorithm = 4, method = \"igraph\") \nEsoph_filt &lt;- FindClusters(Esoph_filt, resolution = 0.6, algorithm = 4, method = \"igraph\") \nEsoph_filt &lt;- FindClusters(Esoph_filt, resolution = 0.8, algorithm = 4, method = \"igraph\") \nEsoph_filt &lt;- FindClusters(Esoph_filt, resolution = 1.0, algorithm = 4, method = \"igraph\") \nEsoph_filt &lt;- FindClusters(Esoph_filt, resolution = 1.2, algorithm = 4, method = \"igraph\")\n\n\nclustree(Esoph_filt, prefix = \"SCT_snn_res.\") # we are going to use resolution 0.2 for Esoph in mm10\n\n\nDimPlot(Esoph_filt, group.by = \"SCT_snn_res.0.2\") & palette_d\nDimPlot(Esoph_filt, group.by = \"SCT_snn_res.0.3\") & palette_d\nDimPlot(Esoph_filt, group.by = \"SCT_snn_res.0.4\") & palette_d\n\nDimPlot(Esoph_filt, group.by = \"SCT_snn_res.0.2\", split.by = \"condition\") & palette_d\n\n\n# number of genes per cell\nFeaturePlot(Esoph_filt, features = \"nFeature_spliced\") & palette # no huge heterogeneities\nFeaturePlot(Esoph_filt, features = \"percent.mt\") & palette \n\nSeeing again the plots after rerunning the analysis without the cells from clusters 4 and 7, we choose resolution 0.2 with 5 clusters.\nAlso, very important: cluster 5 is specific to condition Old_DEN\nNow, we have 5 clusters in our data (resolution 0.2), which, after seeing their genes, could be annotated like: - Cluster 1: Basal (B) - Cluster 2 and 4: Basal prolifetaring (BP) - Cluster 3: differentiated (DIF) - Cluster 5: basal (B)\nThis is a premature proposal, we will decide this later.\n\n# We use resolution 0.2\n# Select resolution for Seurat Clusters:\nIdents(Esoph_filt) = Esoph_filt$SCT_snn_res.0.2\nEsoph_filt$seurat_clusters = Esoph_filt$SCT_snn_res.0.2",
    "crumbs": [
      "Mouse analysis",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>2. Clustering and Cell annotation</span>"
    ]
  },
  {
    "objectID": "Mouse/2_ClusteringCellAnnotation.html#cell-cycle-scoring",
    "href": "Mouse/2_ClusteringCellAnnotation.html#cell-cycle-scoring",
    "title": "2. Clustering and Cell annotation",
    "section": "2.6. Cell cycle scoring",
    "text": "2.6. Cell cycle scoring\n\n# Perform cell cycle scoring on Esoph_filt\nsetwd(\"/home/albax/mcGinn_2021\")\nexp.mat &lt;- read.table(file = \"./cell_cycle_vignette_files/nestorawa_forcellcycle_expressionMatrix.txt\", header = TRUE, as.is = TRUE, row.names = 1)\n\n# A list of cell cycle markers, from Tirosh et al, 2015, is loaded with Seurat.  We can\n# segregate this list into markers of G2/M phase and markers of S phase\ns.genes &lt;- cc.genes$s.genes\ng2m.genes &lt;- cc.genes$g2m.genes\n\nEsoph_filt &lt;- CellCycleScoring(Esoph_filt, s.features = s.genes, g2m.features = g2m.genes, set.ident = TRUE)\n\n\nDimPlot(Esoph_filt, group.by = \"Phase\")",
    "crumbs": [
      "Mouse analysis",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>2. Clustering and Cell annotation</span>"
    ]
  },
  {
    "objectID": "Mouse/2_ClusteringCellAnnotation.html#cluster-annotation-based-on-cellular-composition-dge-featureplots",
    "href": "Mouse/2_ClusteringCellAnnotation.html#cluster-annotation-based-on-cellular-composition-dge-featureplots",
    "title": "2. Clustering and Cell annotation",
    "section": "2.7. Cluster annotation based on cellular composition, DGE, FeaturePlots…",
    "text": "2.7. Cluster annotation based on cellular composition, DGE, FeaturePlots…\nThe mouse esophageal mucosa consists of three layers: stratified epithelium, lamina propia with connective tissue, and muscularis mucosa with smooth muscle. In our data, the authors peeled the muscle (the muscularis mucosa) from the esophagi. So, we should only have the stratified epithelium and maybe lamina propia. The epithelium, in the lumen, is keratinized in mice.\nWe are going to create different signatures depending on:\n\nCell state (resting basal, cycling basal, differentiated) This is what the authors did in McGinn, 2021; or basal, differentiated, cell cycle\n\nBasal: Cdh3, Itgb1, Krt15, Krt14, Krt5, Col17a1, Sox2, Trp63, Itga6\nCell cycle: Gmnn, Mcm6, Mcm2, Cdt1, Pcna, Ccne1, E2f1, Ccne1, Cdc6, Aurkb, Top2a, Ccnb2, Bub1, Ube2c, Aurka, Kif23, Ccnb1, Mki67, Mad2l1, Birc5\nDifferentiating: Krt13, Klf4, Tgm3, Sbsn, Grhl3, Krt4, Notch3, Krtdap\n\nStructure of the epithelium. Stratified epithelium:\n\nLumen\n\nKeratinized cells (final stage of granular): ; Lor, Ivl, Envoplakin, Periplakin, Sprr1a, Sprr1b, Sprr2a1, Sprr2a2, Sprr2a3, Sprr2b, Sprr2d, Sprr2e, Sprr2f, Sprr3; Lor, Flg, Tchp, Ivl, Capza1, S100A1, Sprr1a, Sprr1b, Sprr2a1, Sprr2a2, Sprr2a3, Sprr2b, Sprr2d, Sprr2e, Sprr2f, Sprr3\nSuprabasal cells -&gt; differentiation\n\nGranular: Lor, Flg, Ivl; Tgm3, Krt1, Krt2e, Krt9, Krt10, Dsg1, Dsc1\nSpinous: Krt10, Krt1, Tgm1, Tgm5; Tgm1, Tgm5, Dsg2, Dsg3, Dsg4\n\nBasal cells (can be differentiating or be progenitor cells) -&gt; proliferation, p63+,krt5+,krt7-; Bmi1 progenitor cells, Krt5, Krt14, Krt15; Krt5, Krt14, Tgm2, Bpag1; Itgb1, Trp63, Krt5, Krt14, Krt15; Krt5, Krt14, Bpag1, Tgm2\nBasal lamina: Lama5, Itga6, Itgb4, Bpag2\n\nBasal\n\n\n\n\n\n\n\n\nTip\n\n\n\nkeratinized cells and granular cells could be grouped in one category, the cornified envelope.\n\n\nSummarised by taking the genes in common from the literature:\n\nLumen\n\nKeratinized cells (final stage of granular): Lor, Ivl, Sprr1a, Sprr1b, Sprr2a1, Sprr2a2, Sprr2a3, Sprr2b, Sprr2d, Sprr2e, Sprr2f, Sprr3, Tchp, Capza1, S100A1, Evpl, Ppl\nSuprabasal cells -&gt; differentiation\n\nGranular: Tgm3, Krt1, Krt2e, Krt9, Krt10, Dsg1, Dsc1\nSpinous: Krt10, Krt1, Tgm1, Tgm5, Dsg2, Dsg3, Dsg4\n\nBasal cells (can be differentiating or be progenitor cells) -&gt; proliferation: Krt5, Krt14, Krt15, Tgm2, Bpag1, Tp63, Itgb1\nBasal lamina: Lama5, Itga6, Itgb4\n\nBasal\n\n\n# Taking into account the different sub-levels of the oesophagus epithelium; from Figure S1 Mendeley and Candi E, 2005 (The cornified envelope: a model of cell death in the skin):\n\n# Lumen\n# Keratinized cells (final stage of granular) :\n# FeaturePlot(Esoph_filt, features = c(\"Sprr1a\", \"Sprr1b\", \"Sprr3\", \"Evpl\", \"Ppl\")) & palette & plot_annotation(title = \"Keratinization markers\") & theme(plot.title = element_text(size = 15, face = \"bold\", hjust = 0.5))\n\n# Differentiation markers:\nFeaturePlot(Esoph_filt, features = c(\"Krt13\",  \"Tgm3\", \"Grhl3\", \"Krt4\", \"Notch3\", \"Klf4\", \"Sbsn\", \"Krtdap\")) & palette & plot_annotation(title = \"Differentiation markers\") & theme(plot.title = element_text(size = 15, face = \"bold\", hjust = 0.5))\n\n# Suprabasal cell markers\n# FeaturePlot(Esoph_filt, features = c(\"Krt15\", \"Trp63\", \"Krt5\", \"Krt14\")) & palette & plot_annotation(title = \"Suprabasal cell markers\") & theme(plot.title = element_text(size = 15, face = \"bold\", hjust = 0.5))\n\n# Basal cell markers (can be proliferating or be progenitor cells):\nFeaturePlot(Esoph_filt, features = c(\"Krt5\", \"Krt14\", \"Krt15\", \"Trp63\", \"Itgb1\", \"Itgb4\", \"Col17a1\")) & plot_annotation(title = \"Basal cell markers\") &\n  theme(plot.title = element_text(size = 15, face = \"bold\", hjust = 0.5)) & palette #Mki67 are proliferating cells!!!!!\n\nFeaturePlot(Esoph_filt, features = c(\"Mki67\", \"Cenpf\", \"Cenpa\")) & plot_annotation(title = \"Proliferating basal cell markers\") & theme(plot.title = element_text(size = 15, face = \"bold\", hjust = 0.5)) & palette #Mki67 are proliferating cells!!!!!\n\n# Basal lamina cell markers\n# FeaturePlot(Esoph_filt, features = c(\"Lama5\", \"Itga6\", \"Itgb4\")) + plot_annotation(title = \"Basal lamina cell markers\") &\n#  theme(plot.title = element_text(size = 15, face = \"bold\", hjust = 0.5)) & palette\n\n\n# Taking into account the three clusters from McGinn et al 2021 (CB, RB and DIF):\n\n# Cycling basal markers(CB), cells that have high expression of cell cycle genes:\nFeaturePlot(Esoph, features = c(\"Gmnn\", \"Mcm6\", \"Mcm2\", \"Cdt1\", \"Pcna\", \"Ccne1\", \"E2f1\", \"Cdc6\", \"Aurkb\", \"Top2a\", \"Ccnb2\", \"Bub1\", \"Ube2c\", \"Aurka\", \"Kif23\", \"Ccnb1\", \"Mki67\", \"Mad2l1\", \"Birc5\")) & plot_annotation(title = \"Cycling basal markers(CB)\") & theme(plot.title = element_text(size = 15, face = \"bold\", hjust = 0.5)) & palette\n\n# Resting basal markers (RB):\nFeaturePlot(Esoph_filt, features = c(\"Col17a1\", \"Trp63\", \"Krt14\", \"Itga6\", \"Itgb1\")) & plot_annotation(title = \"Resting basal markers (RB)\") & theme(plot.title = element_text(size = 15, face = \"bold\", hjust = 0.5)) & palette\n\n# Differentiation markers (DIF):\nFeaturePlot(Esoph_filt, features = c(\"Tgm3\", \"Krt13\", \"Grhl3\", \"Krt4\", \"Notch3\", \"Klf4\", \"Sbsn\", \"Krtdap\")) & plot_annotation(title = \"Differentiation markers (DIF)\") & theme(plot.title = element_text(size = 15, face = \"bold\", hjust = 0.5)) & palette\n\n\n## Dot plot of some characteristic markers:\nDotPlot(Esoph, features = c(\"Mki67\",\"Krt14\",\"Col17a1\",\"Krt5\",\"Sbsn\",\"Krtdap\"), cols = c(\"grey\", \"red\"),dot.scale = 10) + RotatedAxis()",
    "crumbs": [
      "Mouse analysis",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>2. Clustering and Cell annotation</span>"
    ]
  },
  {
    "objectID": "Mouse/2_ClusteringCellAnnotation.html#scomatic-preparation",
    "href": "Mouse/2_ClusteringCellAnnotation.html#scomatic-preparation",
    "title": "2. Clustering and Cell annotation",
    "section": "SComatic preparation",
    "text": "SComatic preparation\nSComatic needs a TSV metadata file that relates each cell barcode with each “Cell type” annotation. The annotation will depend on how much granularity we need or is adequate to cal lsomatic variants from single cell transcriptomics. Here, the library design plays a very important role.\n\n\n\nLibrary design\n\n\n\n\n\nCancer cell fraction relation\n\n\n\nSave cell barcodes with cell types in TSV format (SComatic)\nFor SComatic, save cell barcodes with cell types: (first column is barcode and second column is cell type)\n\n# colnames &lt;- c(\"Index\",\"Cell_type\")\n\n#df &lt;- data.frame(Index = Cells(Esoph_filt), Cell_type = Esoph_filt@meta.data$cellType)\n\n# delete suffix??\n# df$\"Index\" &lt;- sapply(strsplit(df$\"Index\", \"-\"), `[`, 1)\n\n# write.table(df, file = './output/esoph_celltype.tsv', col.names = TRUE, row.names = FALSE, sep = '\\t')",
    "crumbs": [
      "Mouse analysis",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>2. Clustering and Cell annotation</span>"
    ]
  },
  {
    "objectID": "Mouse/2_ClusteringCellAnnotation.html#annotation-of-clusters-based-on-known-canonical-markers-of-each-cluster",
    "href": "Mouse/2_ClusteringCellAnnotation.html#annotation-of-clusters-based-on-known-canonical-markers-of-each-cluster",
    "title": "2. Clustering and Cell annotation",
    "section": "Annotation of clusters (based on known canonical markers of each cluster)",
    "text": "Annotation of clusters (based on known canonical markers of each cluster)\nAnnotate each mouse .tsv “Cell_type” as: Epi; so that in Step 3 of SComatic we obtain a .tsv with 1 “cluster”\n\n ## Rearrange cluster order to follow differentiation axis (for visualization purposes) # 9 clusters\nlevels(Esoph_filt) &lt;- c(2,4,1,3,5) # from less differentiated to most (basal to luminal)\n\n# we have 5 clusters in Esoph_filt\n# now, we want to just annotate Epi (all the cells in our Esoph_filt are Epithelial)\nnew.cluster.id &lt;- c(\"Epi\", \"Epi\", \"Epi\", \"Epi\", \"Epi\")\n\nnames(new.cluster.id) &lt;- levels(Esoph_filt)\nEsoph_filt &lt;- RenameIdents(Esoph_filt, new.cluster.id)\n\nEsoph_filt[[\"cellType\"]] &lt;- Idents(Esoph_filt) # include it in the metadata\n\n# Create a new meta.data column named cellType_B that adds _lib1 if the library_ID is llib1, and adds _lib4 if the Library_ID is lib2\nEsoph_filt$cellType_B &lt;- paste0(Esoph_filt$Library_ID, \"_\", Esoph_filt$cellType)\nEsoph_filt$cellType_B &lt;- as.factor(Esoph_filt$cellType_B)\n\n\n# Get the unique sample IDs\nsample_names &lt;- unique(Esoph_filt@meta.data$Sample_name)\n\n# Create the .tsv files for each sample (we will have 16 different tsv files, one for each .bam)\ntsv_file &lt;- function(seurat_obj, sample_names) {\n  for (sample in sample_names) {\n    # Filter the data for the current sample\n    sample_data &lt;- seurat_obj@meta.data %&gt;%\n      filter(Sample_name == sample)\n    \n    # Add the Index column with the correct rownames and apply the transformation\n    sample_data$Index &lt;- sapply(strsplit(rownames(sample_data), \"-\"), `[`, 1)\n    \n    # Select the required columns\n    sample_data &lt;- sample_data %&gt;%\n      select(Index, Cell_type = cellType_B) # Cell_type is a meta.data feature like \"cellType_B\"\n    \n    # Define the file name\n    sample_parts &lt;- strsplit(sample, \"_\")[[1]]\n    file_name &lt;- paste0(\"./output/esoph_markers_scomatic_\", sample_parts[2], \"_\", sample_parts[1], \".tsv\")\n    \n    # Write the data to a .tsv file\n    write.table(sample_data, file = file_name, sep = \"\\t\", row.names = FALSE, col.names = TRUE, quote = FALSE)\n  }\n}\n\ntsv_file(Esoph_filt, sample_names)\n\n\n# Check if we have taken all the rows:\noutput_dir &lt;- \"./output/\"\n\n# Get a list of all .tsv files in the directory\ntsv_files &lt;- list.files(path = output_dir, pattern = \"^esoph_markers_scomatic_.*\\\\.tsv$\", full.names = TRUE)\n\n# Initialize a data frame to store the file names and row counts\nrow_counts &lt;- data.frame(File = character(), Rows = integer(), stringsAsFactors = FALSE)\n\n# Loop through each file, read the data, and count the rows\nfor (file in tsv_files) {\n  # Read the data from the .tsv file\n  data &lt;- read.table(file, sep = \"\\t\", header = TRUE)\n  \n  # Get the number of rows\n  num_rows &lt;- nrow(data)\n  \n  # Add the file name and row count to the data frame\n  row_counts &lt;- row_counts %&gt;%\n    add_row(File = basename(file), Rows = num_rows)\n}\n\ntotal_rows &lt;- sum(row_counts$Rows)\ntotal_rows\n\ndim(Esoph_filt)",
    "crumbs": [
      "Mouse analysis",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>2. Clustering and Cell annotation</span>"
    ]
  },
  {
    "objectID": "Mouse/2_ClusteringCellAnnotation.html#scvelo-preparation",
    "href": "Mouse/2_ClusteringCellAnnotation.html#scvelo-preparation",
    "title": "2. Clustering and Cell annotation",
    "section": "scVelo preparation",
    "text": "scVelo preparation\n\nCluster annotation for scvelo\nLooking at our umap, with resolution 0.2, we will take 3 clusters (Basal, Suprabasal, Epi_DEN), but annotated differently, in 5 names: - Cluster 1: “Basal 1” - Cluster 2: “Basal 2” - Cluster 3: “Suprabasal” - Cluster 4: “Basal 3” - Cluster 5: “Epithelial_DEN”\n\nDimPlot(Esoph_filt, group.by = \"SCT_snn_res.0.2\") & palette_d\n\n\n# make sure we are using the idents we want right now:\nIdents(Esoph_filt) &lt;- Esoph_filt$SCT_snn_res.0.2\nEsoph_filt$seurat_clusters &lt;- Esoph_filt$SCT_snn_res.0.2\n\n## Rearrange cluster order to follow differentiation axis (for visualization purposes) \nlevels(Esoph_filt) &lt;- c(1, 2, 4, 3, 5) # from less differentiated to most (basal to luminal)\n# clusters 1 2 and 4 are basal (red, orange and blue)\n# cluster 3 (green) is suprabasal\n# cluster 5 is specific of condition sample_DEN \n\nnew.cluster.ids &lt;- c(\"Basal_1\", \"Basal_2\", \"Basal_3\", \"Suprabasal\", \"Epithelial_DEN\") # 1, 2, 4, 3, 5\nnames(new.cluster.ids) &lt;- levels(Esoph_filt)\nEsoph_filt &lt;- RenameIdents(Esoph_filt, new.cluster.ids)\n\n\nIdents(Esoph_filt) &lt;- Esoph_filt$annot_scvelo\n\n# Annotated PCA and UMAP plots:\nDimPlot(Esoph_filt, reduction = \"pca\", label = TRUE, pt.size = 0.5) + NoLegend() & palette_d\n\nDimPlot(Esoph_filt, reduction = \"umap\", label = TRUE, pt.size = 0.5) & palette_d\n\n\nDimPlot(Esoph_filt, reduction = \"umap\", label = TRUE, pt.size = 0.5, split.by = \"condition\") & palette_d\n\n\n## Remaining annotation using top markers for every cluster compared to all remaining ones, reporting only the positive ones\nEsoph_filt.markers &lt;- FindAllMarkers(Esoph_filt, only.pos = TRUE, min.pct = 0.25, logfc.threshold = 0.25) # restrict to features with a min of 0.25 logFC\n# write.table(Esoph_filt.markers, file = './output/Esoph_markers_filt.txt', col.names = TRUE, row.names = TRUE, sep = '\\t')\nEsoph_filt.markers &lt;- read.csv(\"./output/Esoph_markers_filt.txt\", sep = \"\\t\")\n\nTopMarkers &lt;- Esoph_filt.markers %&gt;% group_by(cluster) %&gt;% top_n(n = 25, wt = avg_log2FC) # show just top 25 per cluster\n\nTopMarkers %&gt;% write.csv(\"/home/albax/mcGinn_2021/output/Esoph_TopMarkers.csv\")\nclusterB1_markers &lt;- TopMarkers[TopMarkers$cluster == \"Basal_1\", ]  # Basal_1\nclusterB2_markers &lt;- TopMarkers[TopMarkers$cluster == \"Basal_2\", ]  # Basal_2\nclusterB3_markers &lt;- TopMarkers[TopMarkers$cluster == \"Basal_3\", ]  # Basal_3\nclusterSB_markers &lt;- TopMarkers[TopMarkers$cluster == \"Suprabasal\", ]  # Suprabasal\nclusterEpDEN_markers &lt;- TopMarkers[TopMarkers$cluster == \"Epithelial_DEN\", ]  # Epithelial_DEN\n\n\nEsoph_filt.markers &lt;- read.csv(\"./output/Esoph_markers_clusts.txt\", sep = \"\\t\")\n\nTopMarkers &lt;- Esoph_filt.markers %&gt;% group_by(cluster) %&gt;% top_n(n = 25, wt = avg_log2FC) # show just top 25 per cluster\n\nB1_markers &lt;- TopMarkers[TopMarkers$cluster == 'Basal_1', ]\nB2_markers &lt;- TopMarkers[TopMarkers$cluster == 'Basal_2', ]\nB3_markers &lt;- TopMarkers[TopMarkers$cluster == 'Basal_3', ]\nDEN_markers &lt;- TopMarkers[TopMarkers$cluster == 'Epithelial_DEN', ]\nsuprabasal_markers &lt;- TopMarkers[TopMarkers$cluster == 'Suprabasal', ]\n\n\n\nConversion into h5ad object (export to scvelo)\n\n.libPaths(\"/home/albax/miniforge3/envs/seuratdisk/lib/R/library\")\n\n# Esoph_filt@meta.data$annot_scvelo &lt;- as.factor(Esoph_filt@meta.data$annot_scvelo)\n\nlibrary(SeuratDisk) # facilitates conversion between h5Seurat and AnnData objects, i.e. interoperability between Seurat and Scanpy\n\n# Make RNA assay (raw counts, which is a copy of spliced assay) default:\nDefaultAssay(Esoph_filt) &lt;- \"RNA\"\n\nremove_scaledata &lt;- function(assay) {\n    assay@scale.data &lt;- matrix(nrow = 0, ncol = 0)\n    return(assay)\n}\n\ncounts_to_integer &lt;- function(assay) {\n    assay@counts@x &lt;- as.integer(assay@counts@x)\n    return(assay)\n}\n\nremove_normalization &lt;- function(assay) {\n    assay@data &lt;- assay@counts\n    return(assay)\n}\n\nEsoph_filt@assays &lt;- lapply(Esoph_filt@assays, remove_scaledata)\nEsoph_filt@assays &lt;- lapply(Esoph_filt@assays, counts_to_integer)\nEsoph_filt@assays &lt;- lapply(Esoph_filt@assays, remove_normalization)\n\n# Add a new metadata column so that cell types are stored as strings, and not as numbers in the anndata\nEsoph_filt@meta.data$annot_scvelo_names &lt;- as.character(Esoph_filt@meta.data$annot_scvelo)\n\n# File conversion:\nSaveH5Seurat(Esoph_filt, filename = \"Esoph.h5Seurat\", overwrite=TRUE)\nConvert(\"Esoph.h5Seurat\", dest = \"h5ad\", overwrite=TRUE)\n\nSave seurat object:\n\nsaveRDS(Esoph_filt, file = \"./output/esoph_star_filtered_mm10.rds\")",
    "crumbs": [
      "Mouse analysis",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>2. Clustering and Cell annotation</span>"
    ]
  },
  {
    "objectID": "Mouse/2_ClusteringCellAnnotation.html#normalization-of-counts",
    "href": "Mouse/2_ClusteringCellAnnotation.html#normalization-of-counts",
    "title": "2. Clustering and Cell annotation",
    "section": "Normalization of counts",
    "text": "Normalization of counts\nWe are going to normalize the data by total counts (in each library-Sequencing ID). For that, we have to sum all the columns.\n\nlevels(Esoph_filt@meta.data$Sample_name)\nsummary(Esoph_filt[,Esoph_filt@meta.data$Sample_name == 'lib2_run1']@meta.data$Sample_name)\n\nresults_df &lt;- data.frame(Sample_name = character(), Sum_nCount_gene = numeric(), Sum_nFeature_gene = numeric(), stringsAsFactors = FALSE)\ncell_counts_per_sample &lt;- table(Esoph_filt@meta.data$Sample_name) # number of cells per sample_name\n \n# suma de los nCount_gene para cada Sample_name\nfor (i in unique(Esoph_filt$Sample_name)) {\n  # Subset the data based on the current sample name and calculate the sum of nCount_gene\n  sum_count &lt;- sum(Esoph_filt[, Esoph_filt$Sample_name == i]$nCount_gene)\n  sum_feature &lt;- sum(Esoph_filt[, Esoph_filt$Sample_name == i]$nFeature_gene)\n  num_cells &lt;- cell_counts_per_sample[i]\n\n  # Append the results to the results_df\n  results_df &lt;- rbind(results_df, data.frame(Sample_name = i, Sum_nCount_gene = sum_count, Num_cells = num_cells, Sum_nFeature_gene = sum_feature, Num_reads_per_cell = sum_count/num_cells, Num_genes_per_cell = sum_feature/num_cells ))\n}\nnumeric_medians &lt;- apply(results_df[, -1], 2, median)\nmedian_row &lt;- c(Sample_name = \"Median\", numeric_medians)\nresults_df &lt;- rbind(results_df, median_row)\n\nwrite.csv(results_df, \"nCounts_per_Sample_name_Esophfilt.csv\", row.names = FALSE)\n\nSupplementary table from the original paper nCount total is going to ve similar to column 4 * column 6\nSupplementary Table 1 - QC Statistics of scRNAseq data (https://www.nature.com/articles/s41556-021-00679-w#Sec31)\n\n\n\n\n\n\n\n\n\n\n\n\n\nStage\nReplicate no.\nBatch no.\nNumber of cells\nMedian genes/cell\nMedian UMIs/cell\nTotal genes detected\nMedian % mito counts/cell\n\n\n\n\nAdult\n1\n1\n2796\n5153\n30737\n17419\n3.66549437744719\n\n\nAdult\n2\n1\n3344\n5232\n32745.5\n17574\n3.76114454638533\n\n\nAdult\n3\n1\n4059\n5070\n29744\n17843\n4.14769410907473\n\n\nAdult\n1\n2\n1230\n5215\n33187.5\n16440\n3.63571622273852\n\n\nAdult\n2\n2\n2614\n5219\n33970\n17191\n3.25793271016975\n\n\nAdult\n3\n2\n676\n5438\n36246.5\n15707\n3.5389684657119\n\n\n\n\n\n\n\n\n\nWarning:\n\n\n\nSCTransform corrects the counts from your equivalent RNA assay and creates a new assay (typically SCT) where the counts slot is a corrected counts, data is a log transformation of corrected counts+1 and the scale.data are pearson residuals. Typically, the scale.data slot is only generated for the features listed in VariableFeatures(your_object) which is why it’s usually smaller than your SCT data slot. You can tell SCTransform to scale all genes, but whether that’s something you need or not is up to you.",
    "crumbs": [
      "Mouse analysis",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>2. Clustering and Cell annotation</span>"
    ]
  },
  {
    "objectID": "Mouse/2_ClusteringCellAnnotation.html#do-we-find-barcodes-from-epi_den-shared-in-other-clusters",
    "href": "Mouse/2_ClusteringCellAnnotation.html#do-we-find-barcodes-from-epi_den-shared-in-other-clusters",
    "title": "2. Clustering and Cell annotation",
    "section": "Do we find barcodes from Epi_DEN shared in other clusters?",
    "text": "Do we find barcodes from Epi_DEN shared in other clusters?\n\nIs each clone contained completely inside the Epithelial_DEN cluster?(“Epi_DEN_cells”)\nHow are these clones shared with other clusters? How many cells of the clone fall inside Epi_DEN_cells cluster?\n\n\n\nepi_den_CBs &lt;- WhichCells(Esoph_filt, idents = \"Epithelial_DEN\")\nwrite.csv(epi_den_CBs, \"Epithelial_DEN_CBS.txt\", row.names = FALSE)\n\nmetadata &lt;- data.frame(Esoph_filt@meta.data)\nmetadata_cols &lt;- metadata[,c(\"clones\", \"annot_scvelo\"), drop = FALSE]\nwrite.csv(metadata_cols, \"clones_clusters.csv\", row.names = TRUE)\n\nclones_data &lt;- metadata[epi_den_CBs, c(\"clones\", \"annot_scvelo\"), drop = FALSE]\n\nclones_in_Epi_DEN &lt;- as.character(clones_data[[\"clones\"]])\nclones_in_Epi_DEN &lt;- unique(unlist(strsplit(clones_in_Epi_DEN, \",\")))",
    "crumbs": [
      "Mouse analysis",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>2. Clustering and Cell annotation</span>"
    ]
  },
  {
    "objectID": "Mouse/3_Velocity_inference.html",
    "href": "Mouse/3_Velocity_inference.html",
    "title": "3. Inference of velocity",
    "section": "",
    "text": "Slingshot",
    "crumbs": [
      "Mouse analysis",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>3. Inference of velocity</span>"
    ]
  },
  {
    "objectID": "Mouse/3_Velocity_inference.html#slingshot",
    "href": "Mouse/3_Velocity_inference.html#slingshot",
    "title": "3. Inference of velocity",
    "section": "",
    "text": "Import libraries\n\n.libPaths(\"/home/albax/miniforge3/envs/seurat_v4/lib/R/library\")\n\nlibrary(Seurat)\nlibrary(slingshot)\n\nlibrary(grDevices)\nlibrary(RColorBrewer)\nlibrary(ggplot2)\nlibrary(dplyr)\nlibrary(viridis)\n\n\n\nLoad filtered seurat object\n\nEsoph &lt;- readRDS(file = \"mcGinn_2021/output/esoph_star_filtered_mm10.rds\")\n\n# Convert SeuratObject to SingleCellExperiment with Seurat function 'as.SingleCellExperiment()'\nEsoph_sce &lt;- as.SingleCellExperiment(Esoph)\n\n# view idents\nIdents(Esoph) # Basal_1, Basal_2, Basal_3, Suprabasal, Epithelial_DEN\n\n# view metadata columns from sce experiment object, in order to know which one to use \nEsoph_sce@colData\n\n# we will use annot_scvelo which has 5 levels: Basal_1, Basal_2, Basal_3, Suprabasal, Epithelial_DEN\nEsoph_sce@colData$annot_scvelo\n\n# add umap data to sce object\numap_data &lt;- Embeddings(Esoph[[\"umap\"]])  # Extract UMAP data\nreducedDims(Esoph_sce)$UMAP &lt;- umap_data\n\nfactor(Esoph_sce$annot_scvelo)\n\n\n# Run trajectory inference with slingshot\nset.seed(1)\nEsoph_sce &lt;- slingshot(Esoph_sce, clusterLabels = 'annot_scvelo', reducedDim = 'UMAP')\nEsoph_sce$slingParams[\"star.clus\"]\nEsoph_sce$slingParams[\"end.clus\"]\n\nslingshot_obj &lt;- SlingshotDataSet(Esoph_sce)\nslingshot_obj@slingParams$start.clus\nslingshot_obj@slingParams$end.clus\n\n\n\nPlot results\n\n# Plot trajectory (curves how they are called by Slingshot)\npng(\"slingshot_results/plots/Esoph_slingshot_mm10.png\", width=1000, height=1000, units=\"px\")\n\nbreaks &lt;- seq(min(slingPseudotime(Esoph_sce, na=FALSE), na.rm = TRUE), \n               max(slingPseudotime(Esoph_sce, na=FALSE), na.rm = TRUE), \n               length.out = 100)\nviridis_colors &lt;- magma(100)\nplotcol &lt;- viridis_colors[cut(slingPseudotime(Esoph_sce, na=FALSE), breaks = breaks)]\n\nlayout(matrix(c(1, 2), ncol = 2), widths = c(2, 0.25), height = c(1,0.2))\npar(mar=c(5, 4, 4, 1), xpd=TRUE)  # Adjust margins for the main plot\nplot(reducedDims(Esoph_sce)$UMAP, col = plotcol, pch=16, asp = 1)\n\nlines(SlingshotDataSet(Esoph_sce), lwd=2, col='black')\nlines(SlingshotDataSet(Esoph_sce), type = 'lineages', lwd=2, col='black')\n\npar(mar = c(5, 1, 4, 1)) \nplot.new() \nplot.window(xlim = c(0, 1), ylim = c(0, 1))\n\nlegend_image &lt;- as.raster(viridis_colors, ncol=1)\nlegend_width &lt;- 0.7\nlegend_height &lt;- 0.25\nx_left &lt;- (1 - legend_width) / 2\nx_right &lt;- x_left + legend_width\ny_bottom &lt;- (1 - legend_height) / 2\ny_top &lt;- y_bottom + legend_height\nrasterImage(legend_image, x_left, y_bottom, x_right, y_top)\ntext(x = 0.5, y = 0.65, labels = \"Legend\", cex = 1.2, font = 2, pos = 3)\n\ndev.off()\n\n\n# Plot trajectory (curves how they are called by Slingshot)\npng(\"slingshot_results/plots/Esoph_slingshot_curves_mm10.png\", width=1000, height=1000, units=\"px\")\n\nbreaks &lt;- seq(min(slingPseudotime(Esoph_sce, na=FALSE), na.rm = TRUE), \n               max(slingPseudotime(Esoph_sce, na=FALSE), na.rm = TRUE), \n               length.out = 100)\nviridis_colors &lt;- magma(100)\nplotcol &lt;- viridis_colors[cut(slingPseudotime(Esoph_sce, na=FALSE), breaks = breaks)]\n\nlayout(matrix(c(1, 2), ncol = 2), widths = c(2, 0.25), height = c(1,0.2))\npar(mar=c(5, 4, 4, 1), xpd=TRUE)  # Adjust margins for the main plot\nplot(reducedDims(Esoph_sce)$UMAP, col = plotcol, pch=16, asp = 1)\n\nlines(SlingshotDataSet(Esoph_sce), lwd=2, col='black')\n# lines(SlingshotDataSet(Esoph_sce), type = 'lineages', lwd=2, col='black')\n\npar(mar = c(5, 1, 4, 1)) \nplot.new() \nplot.window(xlim = c(0, 1), ylim = c(0, 1))\n\nlegend_image &lt;- as.raster(viridis_colors, ncol=1)\nlegend_width &lt;- 0.7\nlegend_height &lt;- 0.25\nx_left &lt;- (1 - legend_width) / 2\nx_right &lt;- x_left + legend_width\ny_bottom &lt;- (1 - legend_height) / 2\ny_top &lt;- y_bottom + legend_height\nrasterImage(legend_image, x_left, y_bottom, x_right, y_top)\ntext(x = 0.5, y = 0.65, labels = \"Legend\", cex = 1.2, font = 2, pos = 3)\n\ndev.off()\n\n\n\nPlot lineage structure\n\npalette_d &lt;- c(\"#7A0403FF\", \"#FB8022FF\", \"#A2FC3CFF\", \"#28BBECFF\", \"#30123BFF\")\n\npng(\"./velocity/slingshot_results/plots/Esoph_slingshot_trajectories_clusters_mm10.png\", width=1000, height=1000, units=\"px\")\n\nplot(reducedDims(Esoph_sce)$UMAP, col = palette_d[as.numeric(droplevels(Esoph_sce$annot_scvelo))], pch=16, asp = 1)\n\nlines(SlingshotDataSet(Esoph_sce), lwd=2, type = 'lineages', col = 'black')\n\nlegend(x=\"topright\", legend=c(\"Basal_1\", \"Basal_2\", \"Basal_3\", \"Suprabasal\", \"Epithelial_DEN\"), col=palette_d[1:5], pch=16, cex=2)\n\ndev.off()",
    "crumbs": [
      "Mouse analysis",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>3. Inference of velocity</span>"
    ]
  },
  {
    "objectID": "Mouse/3_Velocity_inference.html#scvelo",
    "href": "Mouse/3_Velocity_inference.html#scvelo",
    "title": "3. Inference of velocity",
    "section": "scVelo",
    "text": "scVelo\n\nLoad of .h5ad file\n\n#!/home/albax/miniforge3/envs/ame python3\n# -*- coding: utf-8 -*-\n\"\"\"\nCreated on Jul 26 2024\n\n@author: albax\n\"\"\"\nimport sys\nimport os\n\n# Add the site-packages directory to sys.path\nspecific_path = \"/home/albax/miniforge3/envs/ame/lib/python3.10/site-packages\"\nif specific_path not in sys.path:\n    sys.path.append(specific_path)\n\nsys.path.insert(0, '/home/albax/scvelo/scvelo')\n\nimport scvelo as scv\nimport scanpy as sc\nimport scipy.sparse as sp\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\nfrom matplotlib.colors import ListedColormap\n\nadata = scv.read(\"../Esoph.h5ad\", cache=True)\n\nadata\nadata.layers.keys() # should include spliced and unspliced\nadata.layers['spliced'] # check presence\nadata.layers['unspliced'] # check presence\nadata.var_names = adata.var['_index']\n\nscv.pp.filter_and_normalize(adata, min_shared_counts=20, n_top_genes=2000)\n\n######## deprecated: \n# scv.pp.moments(adata, n_pcs=30, n_neighbors=30)\n################\n\n# 2. Compute PCA with Scanpy\nsc.pp.pca(adata, n_comps=30)\n\n# 2. Compute neighbors with Scanpy\nsc.pp.neighbors(adata, n_pcs=30, n_neighbors=30, use_rep='X_pca')\n\nscv.pp.moments(adata, n_pcs=30, n_neighbors=30) # uses connectivites from step before\n\n# rename levels from annot_scvelo slot\n# rename_dict = {\n#     0: 'Basal_1', # 1\n#     1: 'Basal_2', # 2\n#     2: 'Basal_3', # 3\n#     3: 'Suprabasal', # 4\n#     4: 'Epithelial_DEN', # 5\n# }\n\n# adata.obs['annot_scvelo'] = adata.obs['annot_scvelo'].replace(rename_dict)\n\nDefine functions and colors for plotting:\n\ndef save_stream(adata, file, format=[\"svg\", \"png\"], **kwargs):\n    fig, ax = plt.subplots(figsize=(9, 7))  \n    scv.pl.velocity_embedding_stream(adata, ax=ax, arrow_size=1, cutoff_perc=10, **kwargs)\n    \n    for extension in format:\n        file_name = file + \".\" + extension\n        fig.savefig(file_name, format=extension, bbox_inches='tight')\n    \n    return fig, ax  \n\n\ndef save_grid(adata, file, format=[\"svg\", \"png\"], **kwargs):\n    fig, ax = plt.subplots(figsize=(9, 7))  \n    scv.pl.velocity_embedding_grid(adata, ax=ax, arrow_length=5, arrow_size=3, **kwargs) \n\n    for extension in format:\n        file_name = file + \".\" + extension\n        fig.savefig(file_name, format=extension, bbox_inches='tight')\n    \n    return fig, ax \n\n\ndef save_embedding(adata, file, format=[\"svg\", \"png\"], **kwargs):\n    fig, ax = plt.subplots(figsize=(9, 7)) \n    scv.pl.velocity_embedding(adata, ax=ax, arrow_length=5, arrow_size=3, **kwargs)  \n    \n    for extension in format:\n        file_name = file + \".\" + extension\n        fig.savefig(file_name, format=extension, bbox_inches='tight')\n    \n    return fig, ax  \n\n\npalette = sns.color_palette(\"plasma_r\")\ncolors_d = [\"#7A0403FF\", \"#FB8022FF\", \"#A2FC3CFF\", \"#30123BFF\", \"#28BBECFF\"]\npalette_d = sns.color_palette(colors_d)\n\n\n\nStochastic model\n\nscv.tl.velocity(adata, mode =\"stochastic\") # not good model\nscv.tl.velocity_graph(adata, n_jobs=6) # number of cores to use\n\n# scv.pl.pca(adata, color=\"annot_scvelo\")\n# scv.pl.umap(adata, color=\"annot_scvelo\")\n\n\nSave plots for stochastic model\n\nfig_stream_stoc, ax_stream_stoc = save_stream(adata, file=\"scvelo_results/plots/Esoph_stream_stoch\", format=['svg', 'png'], basis=\"umap\", color=\"annot_scvelo\", palette=palette_d, figsize=(9, 7), legend_loc='right margin', title = \"Stochastic model (stream)\")\n\nfig_grid_stoc, ax_grid_stoc = save_grid(adata, file=\"scvelo_results/plots/Esoph_grid_stoch\", format=['svg', 'png'], basis='umap', color=\"annot_scvelo\", palette=palette_d, figsize=(9, 7), legend_loc='right margin', title = \"Stochastic model (grid)\" )\n\nfig_embedding_stoc, ax_embedding_stoc = save_embedding(adata, file=\"scvelo_results/plots/Esoph_veloc_stoch\", format=['svg', 'png'], basis=\"umap\", color=\"annot_scvelo\", palette=palette_d, figsize=(9, 7), legend_loc='right margin', dpi=200, title = \"Stochastic model (embedding)\")\n\n\n# grid layout for stoc (run everything as chunk)\nfig_combined, axs = plt.subplots(1, 3, figsize=(27, 7))\n\naxs[0].imshow(fig_stream_stoc.canvas.renderer.buffer_rgba())\naxs[0].axis('off')\naxs[1].imshow(fig_grid_stoc.canvas.renderer.buffer_rgba())\naxs[1].axis('off')\naxs[2].imshow(fig_embedding_stoc.canvas.renderer.buffer_rgba())\naxs[2].axis('off') \n\ncombined_file_path = \"scvelo_results/plots/Esoph_combined_plots_stoc\"\nfig_combined.tight_layout()\nfig_combined.savefig(combined_file_path + '_mm10.svg', format='svg', bbox_inches='tight')\nfig_combined.savefig(combined_file_path + '_mm10.png', format='png', dpi=300, bbox_inches='tight')\nplt.show()\n\nSave the .h5ad file with stochastic model\n\ndel adata.raw\nadata.var.rename(columns={'_index': 'index'}, inplace=True)\nadata.obs.rename(columns={'_index': 'index'}, inplace=True)\n\nadata.write(filename = \"scvelo_results/Esoph_stochastic_mm10.h5ad\", compression='gzip')\n\n\n\n\nDeterministic model\n\nscv.tl.velocity(adata, mode = \"deterministic\")\nscv.tl.velocity_graph(adata, n_jobs=6)\n# scv.pl.velocity_embedding_stream(adata, basis=\"umap\", color=\"annot_scvelo\")\n\n# scv.pl.pca(adata, color=\"annot_scvelo\")\n# scv.pl.umap(adata, color=\"annot_scvelo\")\n\n\nSave plots of deterministic model\n\nfig_stream_det, ax_stream_det = save_stream(adata, file=\"scvelo_results/plots/Esoph_stream_det\", format=['svg', 'png'], basis=\"umap\", color=\"annot_scvelo\", palette=palette_d, figsize=(9, 7), legend_loc='right margin', title = \"Deterministic model (stream)\")\n\nfig_grid_det, ax_grid_det = save_grid(adata, file=\"scvelo_results/plots/Esoph_grid_det\", format=['svg', 'png'], basis='umap', color=\"annot_scvelo\", palette=palette_d, figsize=(9, 7), legend_loc='right margin', title = \"Deterministic model (grid)\" )\n\nfig_embedding_det, ax_embedding_det = save_embedding(adata, file=\"scvelo_results/plots/Esoph_veloc_det\", format=['svg', 'png'], basis=\"umap\", color=\"annot_scvelo\", palette=palette_d, figsize=(9, 7), legend_loc='right margin', dpi=200, title = \"Deterministic model (embedding)\")\n\n\n# grid layout for deterministic (run everything as chunk)\nfig_combined, axs = plt.subplots(1, 3, figsize=(27, 7))\n\naxs[0].imshow(fig_stream_det.canvas.renderer.buffer_rgba())\naxs[0].axis('off')\naxs[1].imshow(fig_grid_det.canvas.renderer.buffer_rgba())\naxs[1].axis('off')\naxs[2].imshow(fig_embedding_det.canvas.renderer.buffer_rgba())\naxs[2].axis('off') \n\ncombined_file_path = \"scvelo_results/plots/Esoph_combined_plots_det\"\nfig_combined.tight_layout()\nfig_combined.savefig(combined_file_path + '_mm10.svg', format='svg', bbox_inches='tight')\nfig_combined.savefig(combined_file_path + '_mm10.png', format='png', dpi=300, bbox_inches='tight')\nplt.show()\n\nSave the .h5ad file with dererministic model\n\ndel adata.raw\nadata.var.rename(columns={'_index': 'index'}, inplace=True)\nadata.obs.rename(columns={'_index': 'index'}, inplace=True)\n\nadata.write(filename = \"scvelo_results/Esoph_deterministic_mm10.h5ad\", compression='gzip')\n\n\n\n\nDynamical model\n\nadata = adata[:, adata.var['highly_variable']]  # Only use highly variable genes\nscv.tl.recover_dynamics(adata, n_jobs=6)\nscv.tl.velocity(adata, mode = \"dynamical\")\nscv.tl.velocity_graph(adata, n_jobs=6)\n\nscv.pl.velocity_embedding_stream(adata, basis=\"umap\", color=\"annot_scvelo_names\")\n\n# scv.pl.pca(adata, color=\"annot_scvelo\")\n# scv.pl.umap(adata, color=\"annot_scvelo\")\n\n\nSave plots for dynamical model\n\nfig_stream_dyn, ax_stream_dyn = save_stream(adata, file=\"scvelo_results/plots/Esoph_stream_dyn\", format=['svg', 'png'], basis=\"umap\", color=\"annot_scvelo\", palette=palette_d, figsize=(9, 7), legend_loc='right margin', title = \"Dynamical model (stream)\")\n\nfig_grid_dyn, ax_grid_dyn = save_grid(adata, file=\"scvelo_results/plots/Esoph_grid_det\", format=['svg', 'png'], basis='umap', color=\"annot_scvelo\", palette=palette_d, figsize=(9, 7), legend_loc='right margin', title = \"Dynamical model (grid)\" )\n\nfig_embedding_dyn, ax_embedding_dyn = save_embedding(adata, file=\"scvelo_results/plots/Esoph_veloc_dyn\", format=['svg', 'png'], basis=\"umap\", color=\"annot_scvelo\", palette=palette_d, figsize=(9, 7), legend_loc='right margin', dpi=200, title = \"Dynamical model (embedding)\")\n\n\n# grid layout for dynamical model (run everything as chunk)\nfig_combined, axs = plt.subplots(1, 3, figsize=(27, 7))\n\naxs[0].imshow(fig_stream_dyn.canvas.renderer.buffer_rgba())\naxs[0].axis('off')\naxs[1].imshow(fig_grid_dyn.canvas.renderer.buffer_rgba())\naxs[1].axis('off')\naxs[2].imshow(fig_embedding_dyn.canvas.renderer.buffer_rgba())\naxs[2].axis('off') \n\ncombined_file_path = \"scvelo_results/plots/Esoph_combined_plots_dyn\"\nfig_combined.tight_layout()\nfig_combined.savefig(combined_file_path + '_mm10.svg', format='svg', bbox_inches='tight')\nfig_combined.savefig(combined_file_path + '_mm10.png', format='png', dpi=300, bbox_inches='tight')\nplt.show()\n\nSave the .h5ad file with dynamical model\n\ndel adata.raw\nadata.var.rename(columns={'_index': 'index'}, inplace=True)\nadata.obs.rename(columns={'_index': 'index'}, inplace=True)\n\nadata.write(filename = \"scvelo_results/Esoph_dynamical_mm10.h5ad\", compression='gzip')\n\n\n\nCoherence/Confidence\n\nadata_re = scv.read(\"scvelo_results/Esoph_dynamical_mm10.h5ad\", cache=True)\nadata_re.var_names = adata_re.var['index']\nadata_re\n\n\nscv.tl.velocity_confidence(adata)\nscv.pl.scatter(adata, basis='umap', color=['velocity_length', 'velocity_confidence'], color_map='coolwarm', perc=[0, 100], save=\"scvelo_results/plots/Esoph_dyn_confidence.png\")\n\nadata.obs['annot_scvelo_names'] = adata.obs['annot_scvelo_names'].astype('category')\nscv.tl.rank_velocity_genes(adata, groupby='annot_scvelo_names', min_corr=0.3)\ndf = scv.get_df(adata.uns['rank_velocity_genes']['names'])\ndf.to_csv(\"scvelo_results/Esoph_dyn_genes_rank.csv\")\n\n\n\n\nFull plots\n\nimport matplotlib.pyplot as plt\nimport io\n\ndef get_image_data(fig):\n    \"\"\" Convert a Matplotlib figure to an image array. \"\"\"\n    buf = io.BytesIO()\n    fig.savefig(buf, format='png', bbox_inches='tight', pad_inches=0)\n    buf.seek(0)\n    img = plt.imread(buf)\n    buf.close()\n    return img\n\nfor fig in [fig_stream_dyn, fig_grid_dyn, fig_embedding_dyn, \n            fig_stream_det, fig_grid_det, fig_embedding_det, \n            fig_stream_stoc, fig_grid_stoc, fig_embedding_stoc]:\n    fig.canvas.draw()\n\nfig_combined, axs = plt.subplots(3, 3, figsize=(27, 21)) \n\nimage_data = [\n    get_image_data(fig_stream_dyn),\n    get_image_data(fig_grid_dyn),\n    get_image_data(fig_embedding_dyn),\n    get_image_data(fig_stream_det),\n    get_image_data(fig_grid_det),\n    get_image_data(fig_embedding_det),\n    get_image_data(fig_stream_stoc),\n    get_image_data(fig_grid_stoc),\n    get_image_data(fig_embedding_stoc)\n]\n\nfor ax, img in zip(axs.flat, image_data):\n    ax.imshow(img)\n    ax.axis('off')  # Hide the axes\n\n\nfig_combined.tight_layout()\nfig_combined.savefig(\"scvelo_results/plots/Esoph_combined_plots_mm10.png\", format='png', dpi=300, bbox_inches='tight')\nfig_combined.savefig(\"scvelo_results/plots/Esoph_combined_plots_mm10.svg\", format='svg', dpi=300, bbox_inches='tight')\nfig_combined.savefig(\"scvelo_results/plots/Esoph_combined_plots_mm10.pdf\", format='pdf', dpi=300, bbox_inches='tight')\nplt.show()\n\n\n\nCycling progenitors\n\nscv.tl.score_genes_cell_cycle(adata_re)\n\n# Plot cycling progenitors\nscv.pl.scatter(adata_re, color_gradients=['S_score', 'G2M_score'], edgecolor='gainsboro', linewidths=0.1, colorbar=True, smooth=False, perc=[0, 100], size=6, alpha=1, save=\"scvelo_results/plots/Esoph_filt_dyn_cycling_progenitors.svg\")\nscv.pl.scatter(adata_re, color_gradients=['S_score', 'G2M_score'], edgecolor='gainsboro', linewidths=0.1, colorbar=True, smooth=False, perc=[0, 100], size=6, alpha=1, dpi=300, save=\"scvelo_results/plots/Esoph_filt_dyn_cycling_progenitors.png\")\n\nscv.pl.scatter(adata_re, basis='umap', color='phase', palette=['silver', 'coral', 'royalblue'], size=6, alpha=0.4, dpi=300, title=f\"Cell phase, dynamical model\", save=\"scvelo_results/plots/Esoph_filt_dyn_phase.svg\")\nscv.pl.scatter(adata_re, basis='umap', color='phase', palette=['silver', 'coral', 'royalblue'], size=6, alpha=0.4, dpi=300, title=f\"Cell phase, dynamical model\", save=\"scvelo_results/plots/Esoph_filt_dyn_phase.png\")",
    "crumbs": [
      "Mouse analysis",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>3. Inference of velocity</span>"
    ]
  },
  {
    "objectID": "Mouse/4_VariantCalling.html",
    "href": "Mouse/4_VariantCalling.html",
    "title": "3. SComatic calling",
    "section": "",
    "text": "3.1. Script to call somatic variants\nExecute:",
    "crumbs": [
      "Mouse analysis",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>4. SComatic calling</span>"
    ]
  },
  {
    "objectID": "Mouse/4_VariantCalling.html#script-to-call-somatic-variants",
    "href": "Mouse/4_VariantCalling.html#script-to-call-somatic-variants",
    "title": "3. SComatic calling",
    "section": "",
    "text": "min_ac_cells = 2 (value by default); in HCA was used 1\nmin_cell_types = 2\nmax_cell_types = 1\n\n#!/bin/bash\n# Script with bams separated by run (run1 vs run2). Each run bams are analyzed in a scomatic pipeline. This means, the output of this script will give two final .tsv: one for the run of run1, and another one for the run of run2. Each of these runs/.tsv, will have 8 samples: sample1_Epi, samp2_Epi, samp3_Epi, samp4_Epi, samp5_Epi, samp6_Epi, samp7_Epi, samp8_Epi. \n# There are 6 sample which are control adult, + one sample is old CTL, and + one sample is old DEN. \n# Each of the sample has the key like \"sample1_Epi\", \"samp2_Epi\", etc. \n# DISCLAIMER: ALWAYS USE THE SAME REFERENCE GENOME!!! If you have aligned you rreads with mm10, scomatic will have to be ran with mm10. No coordinates' change with bedtools nor similar strange things. \n# SComatic nowadays has only panel of normales (PON) and editing sites (A-to-I events) for: GRCh38 and mm10. There aren't PON nor editing sites for mouse assembly mm39. \n# The PON for human has been made with GATK data 1000 genomes project. No info of how they did it.\n# The PON for mouse mm10 was done in July 20, using mm10 Tabula muris data. No info of how exactly they did it. \n\n# Run this script in a environment with scomatic installed. \n\nSCOMATIC=~/bin/SComatic-main\n\nrun_names=(\"run1\" \"run2\") # list of runs\n\necho \"Starting Scomatic analysis.\"\n\n\ni=0\nfor run in \"${run_names[@]}\";\ndo\n    i=$((i + 1)) \n\n  # iterate though each bam in the directory where they are located\n  bam_dir=\"/media/storage/mcGinn_2021/STARalignment/bam/${run}\"\n  output_dir=\"/media/storage/mcGinn_2021/scomatic/output/${run}\"\n\n  mkdir -p $output_dir\n\n  logfile=\"$output_dir/scomatic_log.txt\"\n  mkdir -p \"$(dirname \"$logfile\")\"\n\n  log_message() {\n      local log_time\n      log_time=$(date +\"%Y-%m-%d %H:%M:%S\")\n      local message=\"[$log_time] $1\"\n      echo \"$message\" &gt;&gt; \"$logfile\"\n      echo \"$message\"\n  }\n\n  # Initialize log file\n  echo \"### Scomatic Pipeline Log ###\" &gt; \"$logfile\"\n  log_message \"Running scomatic pipeline for run: ${run}\"\n\n\n  # Step 1: Splitting alignment file in cell type specific bams\n  log_message \"Step 1: Splitting alignment file in cell type specific bams...\"\n\n  output_dir1=$output_dir/Step1_BamCellTypes\n  mkdir -p $output_dir1\n  meta_dir=\"/media/storage/mcGinn_2021/scomatic/markers\"\n\n  # Iterate through each BAM file in the bam_dir\n  for bam_file in \"$bam_dir\"/*.bam\n  do\n      # Extract the sample name from the file name\n      base_name=$(basename \"$bam_file\" Aligned.sortedByCoord.out.bam) # run1_lib1\n      sample=${base_name#*_} # remove the prefix up to '_', so that we get only lib1\n\n      echo \"Started sample: $sample\"\n\n      meta_file=\"$meta_dir/${run}/esoph_markers_scomatic_${base_name}.tsv\"\n      \n      # Run the Python script with the appropriate arguments\n      python $SCOMATIC/scripts/SplitBam/SplitBamCellTypes.py --bam \"$bam_file\" \\\n          --meta \"$meta_file\" \\\n          --id \"$sample\" \\\n          --n_trim 5 \\\n          --max_nM 5 \\\n          --max_NH 1 \\\n          --outdir \"$output_dir1\"\n\n      log_message \"Finished sample: $sample\"\n\n      sample_list+=(\"$sample\")\n  done\n\n  # Now, we have each .bam file for each sample located in =$output_dir/Step1_BamCellTypes. In total, 16 .tsv\n  # The bam file will be like: run1_lib1.lib1_Epi.bam\n\n\n  #######################################\n  # Step 2: Collecting base count information\n  \n  REF=/media/storage/reference_genomes/Mus_musculus.GRCm38.dna.primary_assembly.fa\n\n  output_dir2=$output_dir/Step2_BaseCellCounts\n  mkdir -p $output_dir2\n\n  for bam in \"$output_dir1\"/*.bam\n  do\n    \n    # Cell type, which will be lib1 in this case\n    cell_type=$(basename $bam | awk -F'.' '{print $(NF-1)}') # this takes the cell_type from the bam name (the second field to last by separating by '.')\n\n    # Temp folder\n    temp=$output_dir2/temp_${cell_type}\n    mkdir -p $temp\n\n    log_message \"Processing base counts for cell type: $cell_type\"\n\n    # Command line to submit to cluster\n    python $SCOMATIC/scripts/BaseCellCounter/BaseCellCounter.py --bam $bam \\\n      --ref $REF \\\n      --chrom all \\\n      --out_folder $output_dir2 \\\n      --min_bq 30 \\\n      --tmp_dir $temp \\\n      --nprocs 10\n\n    rm -rf $temp\n\n    log_message \"Finished base count processing for cell type: $cell_type\"\n  done\n\n  log_message \"Listing files in $output_dir2 before renaming:\"\n  ls \"$output_dir2\"\n  # Now, we have each .tsv for each sample in output_dir2=$output_dir/Step2_BaseCellCounts\n  # We are going to move both .tsv from the same sample to a new folder inside output_dir2, named after the sample name.\n\n  # echo \"Organizing .tsv files into sample-specific folders...\"\n  log_message \"Renaming .tsv files...\"\n\n\n  for tsv in \"$output_dir2\"/*.tsv\n  do\n      # Create a new directory for the sample\n      # Move the .tsv files corresponding to the sample into the sample directory\n \n      base_name=$(basename \"$tsv\")\n      \n      # lib1.lib1_Epi.tsv ; we want lib1.tsv -&gt; this will be our unique \"cell types\"\n    \n      # Extract run name, and spec cell\n      sample_run=$(echo \"$base_name\" | awk -F'.' '{print $1}') # extracts lib1\n      spec_cell=$(echo \"$base_name\" | awk -F'_' '{print $2}') # extracts Epi.tsv\n\n      new_filename=\"${output_dir2}/${sample_run}_${spec_cell}\" # lib1_Epi.tsv\n\n      # Change each name of the .tsv files by adding its run\n      # mv \"$output_dir2/${sample_name}\"*.tsv \"$sample_dir/${run_name}${sample_name}\"*.tsv\n      mv \"$tsv\" \"$new_filename\"\n\n      # echo \"Moved .tsv files for sample: $sample to $sample_dir\"\n      log_message \"Renamed $tsv to $new_filename\"\n  done\n\n  log_message \"Listing files in $output_dir2 after renaming:\"\n  ls \"$output_dir2\"\n\n  # echo \"Moved the files successfully!\"\n  log_message \"Renamed the files successfully!\"\n\n  #######################################\n  # Step 3: Merging base count matrices\n  log_message \"Step 3: Merging base count matrices...\"\n\n  output_dir3=$output_dir/Step3_BaseCellCountsMerged\n  mkdir -p $output_dir3\n\n  log_message \"Merging base count matrices into a single .tsv file...\"\n\n  python $SCOMATIC/scripts/MergeCounts/MergeBaseCellCounts.py \\\n    --tsv_folder ${output_dir2} \\\n    --outfile ${output_dir3}/${run}.BaseCellCounts.AllCellTypes.tsv\n\n\n  #######################################\n  # Step 4: Detection of somatic mutations\n  log_message \"Step 4: Detection of somatic mutations...\"\n\n  # Step 4.1\n  log_message \"Step 4.1: Variant calling...\"\n  output_dir4=$output_dir/Step4_VariantCalling\n  mkdir -p $output_dir4\n\n  python $SCOMATIC/scripts/BaseCellCalling/BaseCellCalling.step1.py \\\n            --infile ${output_dir3}/${run}.BaseCellCounts.AllCellTypes.tsv \\\n            --outfile ${output_dir4}/${run} \\\n        --max_cell_types 1 \\\n        --min_cell_types 2 \\\n            --ref $REF\n\n\n  # Step 4.2\n  log_message \"Step 4.2: Somatic mutation detection...\"\n  editing=$SCOMATIC/RNAediting/AllEditingSites.mm10.txt\n  PON=$SCOMATIC/PoNs/PoN.scRNAseq.mm10.tsv\n\n  python $SCOMATIC/scripts/BaseCellCalling/BaseCellCalling.step2.py \\\n            --infile ${output_dir4}/${run}.calling.step1.tsv \\\n            --outfile ${output_dir4}/${run}.calling.step2.tsv \\\n            --editing $editing \\\n            --pon $PON\n\n  # extra step: Intersection with bed file\n  log_message \"Extra step: Intersection with bed file...\"\n  bedtools intersect -header -a ${output_dir4}/${run}.calling.step2.tsv -b $SCOMATIC/bed_files_of_interest/UCSC.mm10.without.repeatmasker.bed | awk '$1 ~ /^#/ || $6 == \"PASS\"' &gt; ${output_dir4}/${run}.calling.step2.pass.tsv\n\n  log_message \"Finished scomatic pipeline for ${run} successfully!\"\n\ndone\n\nlog_message \"Pipeline completed successfully for both runs!\"\n\n# Display log file\necho \"Log file saved to: $logfile\"\ncat \"$logfile\"\n\n\n# [matterhorn]\n./SComatic_mouse.sh",
    "crumbs": [
      "Mouse analysis",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>4. SComatic calling</span>"
    ]
  },
  {
    "objectID": "Mouse/4_VariantCalling.html#singlecellgenotype-calling-to-obtain-mutated-cell-barcodes",
    "href": "Mouse/4_VariantCalling.html#singlecellgenotype-calling-to-obtain-mutated-cell-barcodes",
    "title": "3. SComatic calling",
    "section": "3.2. SingleCellGenotype calling to obtain mutated cell barcodes",
    "text": "3.2. SingleCellGenotype calling to obtain mutated cell barcodes\n#!/bin/bash\n# SComatic extra functionality: Computing the genotype for each cell at the variant sites\n# 01/10/2024\n# Author: Alba Méndez Alejandre\n# This is going to allow us to map each variant in the UMAP\n\nSCOMATIC=~/bin/SComatic-main\n\nrun_names=(\"run1\" \"run1\") # list of runs\n\nREF=/media/storage/reference_genomes/Mus_musculus.GRCm38.dna.primary_assembly.fa\nmeta_dir=/media/storage/mcGinn_2021/scomatic/markers\n\ni=0\nfor run in \"${run_names[@]}\";\ndo\n    i=$((i + 1))\n\n    output_dir=\"/media/storage/mcGinn_2021/scomatic/output/${run}\"\n    output_dir1=$output_dir/Step1_BamCellTypes\n    output_dir4=$output_dir/Step4_VariantCalling\n\n    STEP4_2_pass=${output_dir4}/${run}_modif.calling.step2.pass.tsv # modified chr1 to 1 tsv file\n\n    output_dir7=$output_dir/SingleCellAlleles\n    mkdir -p $output_dir7\n    \n    \n    for bam in $(ls -d $output_dir1/*bam);do  \n            cell_type=$(basename $bam | awk -F'.' '{print $(NF-1)}')\n    \n        temp=$output_dir7/temp_${cell_type}\n            mkdir -p $temp\n\n        meta_file=\"$meta_dir/${run}/esoph_markers_scomatic_${run}_${cell_type}.tsv\"\n        \n            python $SCOMATIC/scripts/SingleCellGenotype/SingleCellGenotype.py --bam $bam  \\\n                --infile ${STEP4_2_pass}   \\\n                --nprocs 10   \\\n                --meta $meta_file   \\\n                --outfile ${output_dir7}/${run}_${cell_type}.single_cell_genotype.tsv \\\n                --tmp_dir $temp  \\\n                --ref $REF \\\n            --alt_flag All\n        \n        echo \"bam file is: $bam, Infile is: ${STEP4_2_pass}, meta file is $meta_file and outfile is ${output_dir7}/${cell_type}.single_cell_genotype.tsv\"\n\n            rm -rf $temp\n        done\ndone\n# [matterhorn]\ncd /home/alba/scripts/scomatic\n\n./variants_mapping.sh",
    "crumbs": [
      "Mouse analysis",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>4. SComatic calling</span>"
    ]
  },
  {
    "objectID": "Mouse/4_VariantCalling.html#discard-variants-falling-in-repetitive-regions",
    "href": "Mouse/4_VariantCalling.html#discard-variants-falling-in-repetitive-regions",
    "title": "3. SComatic calling",
    "section": "3.3. Discard variants falling in repetitive regions",
    "text": "3.3. Discard variants falling in repetitive regions\nCreation of bed file with regions overlapping with repetitive ones, in order to remove variants falling in repetitive regions.\nbedtools intersect -v -a mm10_genes.bed -b mm10_RepeatMasker.bed &gt; UCSC.m10.without.repeatmasker.bed\n\nFilter SComatic output to discard variants falling in repetitive regions\nconda activate SComatic\nSCOMATIC=~/bin/SComatic-main\noutput_dir4=/media/storage/mcGinn_2021/scomatic/output/run1/Step4_VariantCalling\n\nbedtools intersect -header -a ${output_dir4}/run1.calling.step2.tsv -b $SCOMATIC/bed_files_of_interest/UCSC.mm10.without.repeatmasker.bed | awk '$1 ~ /^#/ || $6 == \"PASS\"' &gt; ${output_dir4}/run1.calling.step2.pass.tsv\n\noutput_dir4=/media/storage/mcGinn_2021/scomatic/output/run2/Step4_VariantCalling\n\nbedtools intersect -header -a ${output_dir4}/run2.calling.step2.tsv -b $SCOMATIC/bed_files_of_interest/UCSC.mm10.without.repeatmasker.bed | awk '$1 ~ /^#/ || $6 == \"PASS\"' &gt; ${output_dir4}/run2.calling.step2.pass.tsv\n\n\n\n\n\n\nNote:\n\n\n\n*calling.step2.pass.tsv files contain only FILTER = PASS variants that don’t fall in repetitive regions",
    "crumbs": [
      "Mouse analysis",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>4. SComatic calling</span>"
    ]
  },
  {
    "objectID": "Mouse/4_VariantCalling.html#filtering-of-tsvs",
    "href": "Mouse/4_VariantCalling.html#filtering-of-tsvs",
    "title": "3. SComatic calling",
    "section": "3.4. Filtering of TSVs",
    "text": "3.4. Filtering of TSVs\n\nFilter the TSVs with only PASS in FILTER column\n\nseq_ids=(\"run1\" \"run2\")\nwd=\"/media/storage/mcGinn_2021/scomatic/output/\"\n\nfor seq in \"${seq_ids[@]}\"; do\n   \n    awk 'BEGIN {FS=\"\\t\"; OFS=\"\\t\"} NR &lt;= 29 || ($6 == \"PASS\" && !/^#/) {print}' \"${wd}/${seq}/Step4_VariantCalling/${seq}.calling.step2.tsv\" &gt; \"${wd}/${seq}/Step4_VariantCalling/${seq}_filtered.calling.step2.tsv\"\n\ndone\n\n\n\n\n\n\nNote:\n\n\n\n*_filtered.calling.step2.tsv files contain only FILTER = PASS variants, including variants that fall in repetitive regions.\n\n\n\n\nFilter the TSVs with PASS or Multiple_cell_types in FILTER column\nIn order to analyze the variants that are arked solely as “Multiple_cell_types”, we obtain them via an awk command.\n\nseq_ids=(\"run1\" \"run2\")\nwd=\"/media/storage/mcGinn_2021/scomatic/output/\"\n\nfor seq in \"${seq_ids[@]}\"; do\n\n    awk 'BEGIN {FS=\"\\t\"; OFS=\"\\t\"} NR &lt;= 29 || ($6 == \"PASS\" || $6 == \"Multiple_cell_types\") && !/^#/ {print}' \"${wd}/${seq}/Step4_VariantCalling/${seq}.calling.step2.tsv\" &gt; \"${wd}/${seq}/Step4_VariantCalling/${seq}_mult.calling.step2.tsv\"\ndone\n\n\n\n\n\n\nNote:\n\n\n\n*_mult.calling.step2.tsv files contain only FILTER = PASS|Multiple_cell_types variants, including variants that fall in repetitive regions.\n\n\n# [matterhorn]\nconda activate SComatic\nSCOMATIC=~/bin/SComatic-main\noutput_dir4=/media/storage/mcGinn_2021/scomatic/output/run1/Step4_VariantCalling\n\n# for multiple_cell type\nbedtools intersect -header -a ${output_dir4}/run1_mult.calling.step2.tsv -b $SCOMATIC/bed_files_of_interest/UCSC.mm10.withouvt.repeatmasker.bed | awk '$1 ~ /^#/ || $6 == \"PASS\"' &gt; ${output_dir4}/run1_mult.calling.step2.pass.tsv\n\noutput_dir4=/media/storage/mcGinn_2021/scomatic/output/run2/Step4_VariantCalling\n\n# for multiple_cell type\nbedtools intersect -header -a ${output_dir4}/run2_mult.calling.step2.tsv -b $SCOMATIC/bed_files_of_interest/UCSC.mm10.without.repeatmasker.bed | awk '$1 ~ /^#/ || $6 == \"PASS\"' &gt; ${output_dir4}/run2_mult.calling.step2.pass.tsv\n\n\n\n\n\n\nNote:\n\n\n\n*_mult.calling.step2.pass.tsv files contain only FILTER = PASS|Multiple_cell_types variants that don’t fall in repetitive regions",
    "crumbs": [
      "Mouse analysis",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>4. SComatic calling</span>"
    ]
  },
  {
    "objectID": "Mouse/4_VariantCalling.html#convert-the-tsv-files-to-vcf",
    "href": "Mouse/4_VariantCalling.html#convert-the-tsv-files-to-vcf",
    "title": "3. SComatic calling",
    "section": "3.5. Convert the TSV files to VCF",
    "text": "3.5. Convert the TSV files to VCF\nThe program outputs its files in a custom TSV format which makes it very complex to analyze in standard pipelines from variant calling. Thus, we are going to convert it to the standard format file for variant calling in bioinformatics, the VCFv4.3 (https://samtools.github.io/hts-specs/VCFv4.3.pdf). For that, we generated a custom script “3-5_TSVtoVCF.py”.\n\n\n\n\n\n\nWhat is a VCF?\n\n\n\nVCF is a text file format (most likely stored in a compressed manner). It contains meta-information lines (prefixed with “##”), a header line (prefixed with “#”), and data lines each containing information about a position in the genome and genotype information on samples for each position (text fields separated by tabs). Zero length fields are not allowed, a dot (“.”) must be used instead. In order to ensure interoperability across platforms, VCF compliant implementations must support both LF (“”) and CR+LF (“”) newline conventions.\n\n\ncd /media/storage/mcGinn_2021/scomatic\nconda activate d_vep\n\npython 3-5_TSVtoVCF.py --add-info --add-celltypes output/run1/Step4_VariantCalling/run1.calling.step2.tsv output/run1/Step4_VariantCalling/run1.calling.step2.vcf\npython 3-5_TSVtoVCF.py --add-info --add-celltypes output/run2/Step4_VariantCalling/run2.calling.step2.tsv output/run2/Step4_VariantCalling/run2.calling.step2.vcf\n\nCheck VCF files’ integrity\nWe created a VCF file from the filtered SComatic output. Then, we confirmed that the file is properly formatted using both GATK4 and the EBI VCF validator. However, neither tool currently supports VCF version 4.4, they only support up to version 4.3.\n# [matterhorn]\nconda activate samtools\nsamtools faidx Mus_musculus.GRCm39.dna.primary_assembly.faidx\n\nconda activate d_gatk\n\ngatk CreateSequenceDictionary -R Mus_musculus.GRCm39.dna.primary_assembly.fa \n\nREF=~/bin/SComatic-main/reference_genomes/Mus_musculus.GRCm38.dna.primary_assembly.fa \n\ngatk ValidateVariants -V output/run1/Step4_VariantCalling/run1_filtered.calling.step2.vcf -R $REF --validation-type-to-exclude ALLELES\ngatk ValidateVariants -V output/run2/Step4_VariantCalling/run2_filtered.calling.step2.vcf -R $REF --validation-type-to-exclude ALLELES\n\nvcf_validator -i output/run1/Step4_VariantCalling/run1_filtered.calling.step2.vcf -r summary,text,database\nvcf_validator -i output/run2/Step4_VariantCalling/run2_filtered.calling.step2.vcf -r summary,text,database\nBoth files are OK!!!\n📁 Generated files:\n\ngatk ValidateVariants\n\nStandard output message\n\nvcf_validator\n\nStandard output message\n\n\nIt seems that both tools say the converted files are OK, as long as the files are marked as VCFv4.3, because they both don’t support VCFv4.4.",
    "crumbs": [
      "Mouse analysis",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>4. SComatic calling</span>"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Master’s thesis in Bioinformatics and Computational Biology",
    "section": "",
    "text": "Brief description\nThis repository aims to be a log of the overall work i did for my master’s thesis. It covers:\n\nPreprocessing of single-cell RNA-seq data\nClustering and annotation of cell types\nRNA velocity inference to understand cellular dynamics\nSomatic variant calling using SComatic\nFunctional annotation and interpretation of variants\n\nThis work applies variant calling from scRNA-seq to link genetic mutations to cellular phenotypes, using a customized pipeline on mouse and human esophageal data. It highlights the importance of experimental design and filtering for reliable mutation detection.\n\n\n🎯 Objectives\nThe main objective of this work is to assess whether single-cell transcriptomics is suitable for reliable somatic variant detection in mouse esophageal epithelium, and to associate genotype-to-phenotype relations using single cell RNA-seq.\n\nApply and customize variant caller for scRNA-seq in mouse and human esophagus.\nCharacterize the diversity of transcriptomic states in the mouse esophageal epithelium.\nMap variants onto UMAP embeddings.\n\n\n\nTools & Technologies used\n\n(variant caller)\nSeurat, scVelo, Slingshot (transcriptomic analysis & trajectory inference)\nVEP (variant annotation)\n\n\n\nData\nWe obtained the HCA data from previous work (González-Menéndez, 2024), originally taken from: &gt; Madissoon, E., Wilbrey-Clark, A., Miragaia, R.J. et al. scRNA-seq assessment of the human lung, spleen, and esophagus tissue stability after cold preservation. Genome Biol 21, 1 (2020). https://doi.org/10.1186/s13059-019-1906-x\nThe mouse data was obtained from a publicly available dataset.\n\n\n📁 Repository structure\nThe repository holds independent scripts for each dataset:\n├── docs/ # quarto book\n│\n├── Introduction.qmd # installations, brief explanation of configurations used\n│\n├── human/ # 🧍Human analysis\n│ ├── 1_Inspection.qmd # preliminary inspection of the dataset\n│ ├── 2_GeneExpression.qmd # calculate average gene expression for sets of genes\n│ ├── 3_VennDiagrams.qmd # obtain venn diagrams for sets of genes or mutated genes of interest\n│ ├── 4_UMAP_mapping.qmd # map mutated cells in the umap\n│ └── mut_clones_analysis_hca.qmd # modifying seurat_obj@meta.data to add clones\n│\n├── mouse/ # 🐭 Mouse analysis\n│ ├── fastQC/\n│ │   ├── run1/ # multiqc report for the first sequencing run\n│ │   └── run2/ # multiqc report for the second sequencing run\n│ ├── 1-4_merge_seurat_fixedrank.R # script to filter out droplets and doublets from the matrices\n│ ├── 1_DataProcessing.qmd # notebook which contains the bash scripts used to download the files, and oerform the alignment with STARsolo.\n│ ├── 2_ClusteringCellAnnotation.qmd # seurat pipeline to cluster the cells and annotate them\n│ ├── 3_Velocity_inference.qmd # infer velocity and pseudotime trajectory\n│ ├── 4_VariantCalling.qmd  # steps to perform variant calling and pre-filtering processing, as well as TSV to VCF conversion\n│ ├── 5_AnnotationVariants.qmd # exploration of the VEP output\n│ └── 6_GOAnalysis.qmd # GO analysis of the mutated genes\n│\n└──  scripts/ # other general scripts\n  └──  annotate_vep.sh # automated annotation with vep",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "Mouse/5_AnnotationVariants.html",
    "href": "Mouse/5_AnnotationVariants.html",
    "title": "5. Functional annotation of variants",
    "section": "",
    "text": "5.1. Analysis of annotations\nWe are going to view the genes that are drivers, as well as those that are found in the 192 gene panel from Colom 2021 and in the WES data from 9-18 weeks tumos from DEN mice from the same paper.\nAlso, we would like to view if the filtering of repetitive regions filters out variants that have low impact.\nThe list of genes of the 192 mouse gene panel is: Abcb11,Abcc2,Adam10,Adam29,Adcy10,Aff3,Ajuba,Akap9,Akt1,Akt2,Apob,Arid1a,Arid2,Arid5b,Asxl1,Atm,Atp2a2,Atrx,Aurka,B2m,Bbs9,Bcas3,Bcl11b,Bcr,Braf,Brca2,C1s,Cacna1d,Card11,Casp8,Ccnd1,Cdc16,Cdh1,Cdkn2a,Chuk,Clgn,Cnot1,Cntnap4,Cobll1,Col12a1,Copb2,Cr2,Crebbp,Csmd2,Ctcf,Cul3,Cyld,Cyp2b13,Dclk1,Dclre1a,Ddr2,Dicer1,Dmxl2,Dnm2,Dnmt3a,Dst,Egfr,Eif2d,Ep300,Epha2,Erbb2,Erbb3,Erbb4,Ezh2,Fat1,Fat4,Fbn2,Fbxo21,Fbxw7,Fgfr1,Fgfr2,Fgfr3,Flg2,Flt3,Fn1,Gcn1l1,Grin2a,Grm3,Gtf3c5,Hist1h2bm,Hmcn1,Hras,Huwe1,Hydin,Igsf1,Insrr,Iqgap1,Irf6,Kcnh5,Kdm5b,Kdm6a,Kdr,Keap1,Kit,Klrc3,Kmt2c,Kmt2d,Kras,Krt5,Krtap4-9,Loxhd1,Lrp1,Lrp1b,Lrp2,Ltf,Maml1,Mcm7,Met,Mrgprb4,Mtor,Myof,Nf1,Nf2,Nfe2l2,Nfkb1,Nlrp12,Notch1,Notch2,Notch3,Notch4,Nras,Nsd1,Nup214,Opn3,Pard3,Pcdha5,Pced1b,Pde4dip,Peg10,Pign,Pik3ca,Pkhd1,Plcb1,Prex2,Psme4,Ptch1,Pten,Ptprt,Rac1,Rasa1,Rb1,Rbm46,Rhbdf2,Ripk2,Ripk4,Ros1,Rpgrip1,Rpl10,Ryr2,Sall1,Scn10a,Scn11a,Scn1a,Scn3a,Setd2,Setx,Sgk3,Sis,Slc13a1,Smad4,Smarca4,Smo,Snx25,Soat2,Sox2,Spen,St18,Sufu,Synm,Taf2,Tas2r102,Tet2,Tnr,Trp53,Trp63,Trrap,Tsc1,Ttc27,Usp24,Usp26,Usp9x,Vhl,Vmn2r81,Vps13b,Wnk1,Zan,Zfhx3,Zfp39,Zfp457,Zfp521,Zfp644,Zfp750",
    "crumbs": [
      "Mouse analysis",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>5. Functional annotation of variants</span>"
    ]
  },
  {
    "objectID": "Mouse/5_AnnotationVariants.html#wordcloud-of-genes",
    "href": "Mouse/5_AnnotationVariants.html#wordcloud-of-genes",
    "title": "5. Functional annotation of variants",
    "section": "Wordcloud of genes",
    "text": "Wordcloud of genes\n\nlibrary(\"wordcloud\")\n\ndf &lt;- read.table(\"/media/storage/Documents/scRNAseq/SComatic/TextMining/mutatedGenes_mouse.txt\", header=TRUE)\n\npdf('wordcloud_mutatedGenes_mouse.pdf')\nwordcloud(df$name, # terms\n    freq = log2(df$freq), # frequency\n    min.freq = 1, # minimum freq to plot\n    scale=c(2,0.1), # set max and min word size  (we set them to (4, 0.3) when not using log2)\n    max.words=nrow(df), # show top n words\n    random.order=FALSE, # words in decreasing freq\n    rot.per=0.35, # % of vertical words\n    use.r.layout=FALSE, # Use C++ collision detection\n    ordered.colors=TRUE, \n    colors=brewer.pal(8, \"Dark2\")[factor(df$iscancer)]) # no. of different colors and palette\nlegend(\"topright\", legend = levels(factor(df$iscancer)), text.col=brewer.pal(8, \"Dark2\")[unique(factor(df$iscancer))])\ndev.off()",
    "crumbs": [
      "Mouse analysis",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>5. Functional annotation of variants</span>"
    ]
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "Set-up and installations",
    "section": "",
    "text": "Computers\nI used mainly two computers for all the calculations, though the HCA dataset was in a third one, so i had to use it sporadically.\nAll code was executed in computers running Ubuntu 22.04.4 LTS.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Set-up and installations</span>"
    ]
  },
  {
    "objectID": "intro.html#computers",
    "href": "intro.html#computers",
    "title": "Set-up and installations",
    "section": "",
    "text": "matterhorn: main computer. Mainly used for storage and explorative analysis.\nnuptse: used for storage and explorative analysis of HCA dataset.\nfolia: small computing server. Used for clusterization, alignment, etc.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Set-up and installations</span>"
    ]
  },
  {
    "objectID": "intro.html#conda-environments",
    "href": "intro.html#conda-environments",
    "title": "Set-up and installations",
    "section": "Conda environments",
    "text": "Conda environments\nMost of the software was installed using mamba/conda environments when possible.\nmamba config --add channels bioconda\nmamba config --add channels conda-forge\n\nd_rstudio\nState: active Computer: nuptse, folia, matterhorn Purpose: to have a functional RStudio/VSCode installation along with the packages for the kallisto-bustools velocity workflow. Creation: run the following commands to install RStudio along with the packages needed for data analysis.\nmamba create -n d_rstudio -c conda-forge rstudio-desktop jupyter r-seurat\n\nconda activate d_rstudio\n\nmamba install r-devtools r-tidyverse r-zeallot r-ggally bioconductor-bsgenome.mmusculus.ucsc.mm10 bioconductor-dropletutils bioconductor-annotationhub bioconductor-singler\n\n# Install packages from source\nR\n\n# Hard-code the commit for reproducibility\ndevtools::install_github(\"satijalab/seurat-wrappers@73466e361ee759c6b1add58faa3bc4e7a2ee5753\")\n\nq()\n\n# Posterior installations\nmamba install r-velocyto.r\nmamba install -c bioconda bioconductor-slingshot\nmamba install leidenalg # for clustering\nmamba install numpy pandas\nmamba install -c conda-forge r-clustree\nmamba install -c conda-forge r-svglite\n\n# Installing packages to convert to H5AD data\nR\n\n# Hard-code commit for future reproducibility. Skip updates when asked\ndevtools::install_github(\"mojaveazure/seurat-disk@877d4e18ab38c686f5db54f8cd290274ccdbe295\")\n\n\nmamba install -c conda-forge plotly python-kaleido\nmamba install -c plotly plotly-orca\nmamba install -c conda-forge r-processx\nmamba install -c conda-forge r-pals\nmamba install -c conda-forge r-ggvenn r-ggvenndiagram r-venn r-venndiagram\n\n\nSComatic\nState: active Computer: nuptse, folia, matterhorn Purpose: to have an isolated environment with SComatic for scRNA-seq mutation calling\nmamba create -n d_scomatic -c bioconda python=3.7 r-base=3.6.1 samtools datamash bedtools\n\n# You can download a zip file with the repository \"Code\" button in the web\n# Or you can do the same thing in the linux terminal\n# For future reproducibility\nwget -P /home/dario/bin/ https://github.com/cortes-ciriano-lab/SComatic/archive/f515f4ee3e7c128600215d21992c051c16e0a03f.zip\n# To grab the latest branch\nwget -P /home/dario/bin/ https://github.com/cortes-ciriano-lab/SComatic/archive/main.zip\n\nunzip *zip\nmv SComatic-main SComatic\n\n# You could also clone the repository to keep the files up to date if needed\ngit clone --single-branch https://github.com/cortes-ciriano-lab/SComatic.git /path/to/dir/\n\n# I install the remaining dependencies as instructed, using the “requirements.txt” file in the repository.\nmamba activate d_scomatic\n\npip install -r requirements.txt",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Set-up and installations</span>"
    ]
  },
  {
    "objectID": "Mouse/6_GOAnalysis.html",
    "href": "Mouse/6_GOAnalysis.html",
    "title": "6. Gene Ontology Analysis",
    "section": "",
    "text": "gene_list &lt;- read_tsv(\"mutated_genes_mouse.tsv\")\n\n# RANK LIST\ngene_list$all_donors &lt;- rowSums(gene_list[,c(2,3,4,5,6,7)], na.rm = TRUE)\ngene_list_all &lt;- gene_list[, c(1,8)]\ngene_list_all &lt;- gene_list_all[gene_list_all$gene_symbol != \"Unknown\",]\n\n#GO\n#lista con los genes de gene_list_all\ngo_genes &lt;- as.character(gene_list_all$gene_symbol)\n\n# Crear el vector all_genes con los símbolos de todos los human genes para \"universe\"\nall_genes &lt;- keys(org.Mm.eg.db, keytype = \"SYMBOL\")\n\n#enrichment analyis con ontologia BIOPROCESES\n\nall_donors_GO &lt;- enrichGO(gene = go_genes,\n                          universe = all_genes,\n                          keyType = \"SYMBOL\",\n                          OrgDb = org.Mm.eg.db,\n                          ont = \"BP\",\n                          pAdjustMethod = \"BH\",\n                          qvalueCutoff = 0.05,\n                          readable = FALSE)\n\npdf(\"dotplot_GOmouse.pdf\", height = 9)\ndotplot(all_donors_GO, showCategory=20, font.size = 8, title= \"\")\ndev.off()",
    "crumbs": [
      "Mouse analysis",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>6. Gene Ontology Analysis</span>"
    ]
  },
  {
    "objectID": "Mouse/5_AnnotationVariants.html#analysis-of-annotations",
    "href": "Mouse/5_AnnotationVariants.html#analysis-of-annotations",
    "title": "5. Functional annotation of variants",
    "section": "",
    "text": "The list of genes in WES is much bigger, there are 31284 genes.\nintogen human drivers need to be converted with BioMart from mouse to human genes previously.\n\n\n\n\n\n\n\nWarning! this is the structure of the CSQ value from INFO column:\n\n\n\nAllele|Consequence|IMPACT|SYMBOL|Gene|Feature_type|Feature|BIOTYPE|EXON|INTRON|HGVSc|HGVSp|cDNA_position|CDS_position|Protein_position|Amino_acids|Codons|Existing_variation|DISTANCE|STRAND|FLAGS|VARIANT_CLASS|SYMBOL_SOURCE|HGNC_ID|CANONICAL|MANE|TSL|APPRIS|CCDS|ENSP|SWISSPROT|TREMBL|UNIPARC|UNIPROT_ISOFORM|GENE_PHENO|SIFT|DOMAINS|miRNA|AF|AFR_AF|AMR_AF|EAS_AF|EUR_AF|SAS_AF|AA_AF|EA_AF|gnomAD_AF|gnomAD_AFR_AF|gnomAD_AMR_AF|gnomAD_ASJ_AF|gnomAD_EAS_AF|gnomAD_FIN_AF|gnomAD_NFE_AF|gnomAD_OTH_AF|gnomAD_SAS_AF|MAX_AF|MAX_AF_POPS|CLIN_SIG|SOMATIC|PHENO|PUBMED|MOTIF_NAME|MOTIF_POS|HIGH_INF_POS|MOTIF_SCORE_CHANGE|TRANSCRIPTION_FACTORS",
    "crumbs": [
      "Mouse analysis",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>5. Functional annotation of variants</span>"
    ]
  },
  {
    "objectID": "Mouse/5_AnnotationVariants.html#section",
    "href": "Mouse/5_AnnotationVariants.html#section",
    "title": "5. Functional annotation of variants",
    "section": "5.2.",
    "text": "5.2.\n\nWordcloud of genes\n\nlibrary(\"wordcloud\")\n\ndf &lt;- read.table(\"/media/storage/Documents/scRNAseq/SComatic/TextMining/mutatedGenes_mouse.txt\", header=TRUE)\n\npdf('wordcloud_mutatedGenes_mouse.pdf')\nwordcloud(df$name, # terms\n    freq = log2(df$freq), # frequency\n    min.freq = 1, # minimum freq to plot\n    scale=c(2,0.1), # set max and min word size  (we set them to (4, 0.3) when not using log2)\n    max.words=nrow(df), # show top n words\n    random.order=FALSE, # words in decreasing freq\n    rot.per=0.35, # % of vertical words\n    use.r.layout=FALSE, # Use C++ collision detection\n    ordered.colors=TRUE, \n    colors=brewer.pal(8, \"Dark2\")[factor(df$iscancer)]) # no. of different colors and palette\nlegend(\"topright\", legend = levels(factor(df$iscancer)), text.col=brewer.pal(8, \"Dark2\")[unique(factor(df$iscancer))])\ndev.off()",
    "crumbs": [
      "Mouse analysis",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>5. Functional annotation of variants</span>"
    ]
  }
]